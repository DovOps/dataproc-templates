{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f4d4022-15d2-4171-9460-425dcd7d9334",
   "metadata": {},
   "source": [
    "# MSSQL to POSTGRES Migration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5baf865-b719-4c0f-bc2c-4ac062cd7927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e7cc8e-c949-4d7d-a9f8-1ecd0d827f4b",
   "metadata": {},
   "source": [
    "#### References\n",
    "- [DataprocPySparkBatchOp reference](https://google-cloud-pipeline-components.readthedocs.io/en/google-cloud-pipeline-components-1.0.0/google_cloud_pipeline_components.experimental.dataproc.html)\n",
    "- [Kubeflow SDK Overview](https://www.kubeflow.org/docs/components/pipelines/sdk/sdk-overview/)\n",
    "- [Dataproc Serverless in Vertex AI Pipelines tutorial](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage3/get_started_with_dataproc_serverless_pipeline_components.ipynb)\n",
    "- [Build a Vertex AI Pipeline](https://cloud.google.com/vertex-ai/docs/pipelines/build-pipeline)\n",
    "\n",
    "This notebook is built to run a Vertex AI User-Managed Notebook using the default Compute Engine Service Account.\n",
    "Check the Dataproc Serverless in Vertex AI Pipelines tutorial linked above to learn how to setup a different Service Account.\n",
    "#### Permissions\n",
    "Make sure that the service account used to run the notebook has the following roles:\n",
    "- roles/aiplatform.serviceAgent\n",
    "- roles/aiplatform.customCodeServiceAgent\n",
    "- roles/storage.objectCreator\n",
    "- roles/storage.objectViewer\n",
    "- roles/dataproc.editor\n",
    "- roles/dataproc.worker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31512ac6-a760-4f95-bb17-e5fc81b7d995",
   "metadata": {},
   "source": [
    "## Step 1: Install Libraries\n",
    "#### Run Step 1 one time for each new notebook instance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1feb899d-ea30-4ae5-9e19-3d3c85d5b663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets===8.0.0 in /opt/conda/lib/python3.7/site-packages (8.0.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets===8.0.0) (6.15.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets===8.0.0) (4.0.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets===8.0.0) (7.33.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets===8.0.0) (5.3.0)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets===8.0.0) (3.0.2)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets===8.0.0) (7.3.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets===8.0.0) (21.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets===8.0.0) (5.9.1)\n",
      "Requirement already satisfied: debugpy>=1.0 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets===8.0.0) (1.6.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets===8.0.0) (6.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets===8.0.0) (0.1.3)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets===8.0.0) (1.5.5)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets===8.0.0) (23.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets===8.0.0) (5.1.1)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets===8.0.0) (2.12.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets===8.0.0) (3.0.30)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets===8.0.0) (59.8.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets===8.0.0) (0.18.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets===8.0.0) (4.8.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets===8.0.0) (0.7.5)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets===8.0.0) (0.2.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets===8.0.0) (0.8.3)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.7/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets===8.0.0) (0.4)\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in /opt/conda/lib/python3.7/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets===8.0.0) (4.11.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.7/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets===8.0.0) (2.8.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets===8.0.0) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets===8.0.0) (0.2.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->ipykernel>=4.5.1->ipywidgets===8.0.0) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets===8.0.0) (1.16.0)\n",
      "Requirement already satisfied: pymssql in /opt/conda/lib/python3.7/site-packages (2.2.5)\n",
      "Requirement already satisfied: SQLAlchemy in /opt/conda/lib/python3.7/site-packages (1.4.39)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from SQLAlchemy) (4.11.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.7/site-packages (from SQLAlchemy) (1.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->SQLAlchemy) (3.8.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->SQLAlchemy) (4.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install ipywidgets===8.0.0\n",
    "!pip3 install pymssql SQLAlchemy\n",
    "!pip3 install --upgrade google-cloud-pipeline-components kfp --user -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc31237-ea30-475e-8254-b62765fec009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# waititng some time for kernel to restart\n",
    "import os\n",
    "import IPython\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84557378-e132-4cf1-9a05-a2c18d65d404",
   "metadata": {},
   "source": [
    "## Step 2: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f7649c8-a118-42d4-b385-c49be2cc1070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aiplatform\n",
    "from kfp import dsl\n",
    "from kfp.v2 import compiler\n",
    "from datetime import datetime\n",
    "import time\n",
    "import copy\n",
    "import json\n",
    "import pandas as pd\n",
    "from google_cloud_pipeline_components.experimental.dataproc import DataprocPySparkBatchOp\n",
    "import ipywidgets as widgets\n",
    "import sqlalchemy\n",
    "import pymssql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "305eb98c-40c6-4620-97f0-75cd3d78c434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define widget style for the notebook\n",
    "style = {'description_width': 'initial','width':'400px'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd3ac39-28ab-4339-8865-0a7024963bc6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 3: Assign Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c17a10-6166-4c6b-9297-127dcbb8c1be",
   "metadata": {},
   "source": [
    "### Step 3.1 Common Parameters\n",
    "##### PROJECT : GCP project-id\n",
    "##### REGION : GCP region\n",
    "##### GCS_STAGING_LOCATION : GCS staging location to be used for this notebook to store artifacts\n",
    "##### SUBNET : VPC subnet\n",
    "##### JARS : list of jars. For this notebook mssql connectora and postgres connectorjar is required in addition with the dataproc template \n",
    "##### MAX_PARALLELISM : Parameter for number of jobs to run in parallel default value is 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "821480e9-c9a1-42eb-9604-dc33c5881689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a6bd6641fc6437e97fc6e81e799af50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='yadavaja-sandbox', description='PROJECT', placeholder='<project_id>', style=TextStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aaf6df68d57416b828882764a62923c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='us-west1', description='REGION', placeholder='eg. us-central1', style=TextStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ace1f69f77f34284a3e471bff56cc5d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='gs://test-styagi', description='GCS STAGING LOCATION', placeholder='gs://<bucket_name>', style=Tex…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f7cddc2ef3143efa0202668e240b746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='projects/yadavaja-sandbox/regions/us-west1/subnetworks/test-subnet1', description='SUBNET', placeh…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c256742d201e4837997303b9ad761059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=2, description='MAX PARALLELISM', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get GCP Project\n",
    "\n",
    "PROJECT=widgets.Text(value=\"yadavaja-sandbox\",description=\"PROJECT\",placeholder=\"<project_id>\",style=style)\n",
    "display(PROJECT)\n",
    "\n",
    "REGION=widgets.Text(value=\"us-west1\",description=\"REGION\",placeholder=\"eg. us-central1\",style=style, width=\"auto\")\n",
    "display(REGION)\n",
    "\n",
    "GCS_STAGING_LOCATION=widgets.Text(value=\"gs://test-styagi\",placeholder=\"gs://<bucket_name>\",description=\"GCS STAGING LOCATION\",style=style)\n",
    "display(GCS_STAGING_LOCATION)\n",
    "\n",
    "SUBNET=widgets.Text(value=\"projects/yadavaja-sandbox/regions/us-west1/subnetworks/test-subnet1\",placeholder=\"projects/<project-id>/regions/<region-id>/subnetworks/<subnet-name>\",description=\"SUBNET\",style=style)\n",
    "display(SUBNET)\n",
    "\n",
    "MAX_PARALLELISM=widgets.IntText(value=\"2\",description=\"MAX PARALLELISM\",style=style)\n",
    "display(MAX_PARALLELISM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d0d0a9-5556-494d-bde4-0e9998795e5f",
   "metadata": {},
   "source": [
    "### Step 3.2 MSSQL Parameters\n",
    "#### MSSQL_HOST : MSSQL instance ip address\n",
    "#### MSSQL_PORT : MSSQL instance port\n",
    "#### MSSQL_USERNAME : MSSQL username\n",
    "#### MSSQL_PASSWORD : MSSQL password\n",
    "#### MSSQL_DATABASE : name of database that you want to migrate\n",
    "#### MSSQLTABLE_LIST : list of tables you want to migrate eg: ['table1','table2'] else provide an empty list for migration whole database eg : []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dacdf900-5609-45ba-81cc-cfa5d27685ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce3f2ee484940f9bd67c959bf5ef7ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='SQL Server Host')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "971724c5d5a64fbd924c98518ab7d52c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='10.203.210.5', style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d31ca65db5f4e9cbed1ef52c6559434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='SQL Server Port')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe7435bcf4f4e49b4bf556454dfed7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='1433', style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a38efd1aac44369158a0d0168b296f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='SQL Server Username')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "042c8b29a753488595b432128fc94ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='sqlserver', style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8831029aa9594f889bebb45ca8266480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='SQL Server Password')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7723c505020841f9b49121c93376a716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='password123', style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d5a37110eac42c99030d2c7d6121a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='SQL Server Database')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ecfc964f6d4cddbf0ec04062ec1ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='AdvDB', style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e07576662d4d4084af9a4c06508b9638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='SQL Server Input Table List')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26fb8194ac1146f08665e36ce3df77bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='<table1>,<table2>,...', style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acc9ff1d657f43ad96cad1958293b195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='SQL Server Input Partition Column')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25163772e8234616a08d9173ae65d7d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='id', style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60dd7586092f4f179dffaaccd850f3ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='SQL Server Input Lowerbound')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "514563ef0ad444669c6aba8ad0426b34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='11', style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d2df258aaeb4b24be9b21e5e0ba8eb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='SQL Server Input Upperbound')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f11688c54d442d0baf5032b542e092f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='20', style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be581825d5e6418ab4c1272c7c842f1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='No. Of Partitions')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86fc5d08f642462d9cb49116031a481f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='4', style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "display(widgets.Label(\"SQL Server Host\"))\n",
    "MSSQL_HOST=widgets.Text(value=\"10.203.210.5\",style=style)\n",
    "display(MSSQL_HOST)\n",
    "\n",
    "display(widgets.Label(\"SQL Server Port\"))\n",
    "MSSQL_PORT=widgets.Text(value=\"1433\",style=style)\n",
    "display(MSSQL_PORT)\n",
    "\n",
    "display(widgets.Label(\"SQL Server Username\"))\n",
    "MSSQL_USERNAME=widgets.Text(value=\"sqlserver\",style=style)\n",
    "display(MSSQL_USERNAME)\n",
    "\n",
    "display(widgets.Label(\"SQL Server Password\"))\n",
    "MSSQL_PASSWORD=widgets.Text(value=\"password123\",style=style)\n",
    "display(MSSQL_PASSWORD)\n",
    "\n",
    "display(widgets.Label(\"SQL Server Database\"))\n",
    "MSSQL_DATABASE=widgets.Text(value=\"AdvDB\",style=style)\n",
    "display(MSSQL_DATABASE)\n",
    "\n",
    "display(widgets.Label(\"SQL Server Input Table List\"))\n",
    "MSSQLTABLE_LIST=widgets.Text(placeholder=\"<table1>,<table2>,...\",style=style)\n",
    "display(MSSQLTABLE_LIST)\n",
    "\n",
    "display(widgets.Label(\"SQL Server Input Partition Column\"))\n",
    "JDBCTOJDBC_INTPUT_PARTITIONCOLUMN=widgets.Text(value=\"id\",style=style)\n",
    "display(JDBCTOJDBC_INTPUT_PARTITIONCOLUMN)\n",
    "\n",
    "display(widgets.Label(\"SQL Server Input Lowerbound\"))\n",
    "JDBCTOJDBC_INTPUT_LOWERBOUND=widgets.Text(value=\"11\",style=style)\n",
    "display(JDBCTOJDBC_INTPUT_LOWERBOUND)\n",
    "\n",
    "display(widgets.Label(\"SQL Server Input Upperbound\"))\n",
    "JDBCTOJDBC_INTPUT_UPPERBOUND=widgets.Text(value=\"20\",style=style)\n",
    "display(JDBCTOJDBC_INTPUT_UPPERBOUND)\n",
    "\n",
    "display(widgets.Label(\"No. Of Partitions\"))\n",
    "JDBCTOJDBC_NUMOFPARTITIONS=widgets.Text(value=\"4\",style=style)\n",
    "display(JDBCTOJDBC_NUMOFPARTITIONS)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e01a00f-0c36-44f1-93bd-d849c62d5bac",
   "metadata": {},
   "source": [
    "### Step 3.3 POSTGRES Parameters\n",
    "#### POSTGRES_HOST : MSSQL instance ip address\n",
    "#### POSTGRES_PORT : MSSQL instance port\n",
    "#### POSTGRES_USERNAME : MSSQL username\n",
    "#### POSTGRES_PASSWORD : MSSQL password\n",
    "#### POSTGRES_DATABASE : name of database that you want to migrate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35947f0a-860a-46c0-b89e-6be99dea113c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5cb5973b0974e26a1106d20e4f36bdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='PPOSTGRES Server Host')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f967b8d72d8d448dbd0cc8167e8a421b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='10.203.211.3', style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "602edf8b52824530a3c8209b225e3255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='POSTGRES Server Port')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c073242c951495fb06db432e3f8586e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='5432', style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b839391ecbf94e208f21703f11899f6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='POSTGRES Server Username')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "171b0a57a1d74af9b90587e9b9838507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='postgres', style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dadc0b2c6194ad0b93b70a5b3cd12bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='POSTGRES Server Password')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce698eed054c41db9b5dde9545158020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='password123', style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a87648a936fe4e6a958cd60cb608c39b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='POSTGRES Server Database')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbed1b34486540aa9cace8b29014b867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='AdvDB', style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98a2f1f542bc4bb991e452ca08ee28b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='POSTGRES Output Table')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a77f466ec6754be3bd12fa30d6689592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='employees_out_st', style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b3d39c2e2d34b538fd139ddab4e2372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='POSTGRES Output Mode')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "921bb122cd534e8db53b24556ff2af5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='overwrite', style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b47d942699d64d9f9d121941eca88cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='POSTGRES Output Batch Size')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfb4749246514df7acac8f0a510dfd50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='1000', style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(widgets.Label(\"PPOSTGRES Server Host\"))\n",
    "POSTGRES_HOST=widgets.Text(value=\"10.203.211.3\",style=style)\n",
    "display(POSTGRES_HOST)\n",
    "\n",
    "display(widgets.Label(\"POSTGRES Server Port\"))\n",
    "POSTGRES_PORT=widgets.Text(value=\"5432\",style=style)\n",
    "display(POSTGRES_PORT)\n",
    "\n",
    "display(widgets.Label(\"POSTGRES Server Username\"))\n",
    "POSTGRES_USERNAME=widgets.Text(value=\"postgres\",style=style)\n",
    "display(POSTGRES_USERNAME)\n",
    "\n",
    "display(widgets.Label(\"POSTGRES Server Password\"))\n",
    "POSTGRES_PASSWORD=widgets.Text(value=\"password123\",style=style)\n",
    "display(POSTGRES_PASSWORD)\n",
    "\n",
    "display(widgets.Label(\"POSTGRES Server Database\"))\n",
    "POSTGRES_DATABASE=widgets.Text(value=\"AdvDB\",style=style)\n",
    "display(POSTGRES_DATABASE)\n",
    "\n",
    "display(widgets.Label(\"POSTGRES Output Table\"))\n",
    "JDBCTOJDBC_OUTPUT_TABLE=widgets.Text(value=\"employees_out_st\",style=style)\n",
    "display(JDBCTOJDBC_OUTPUT_TABLE)\n",
    "\n",
    "display(widgets.Label(\"POSTGRES Output Mode\"))\n",
    "JDBCTOJDBC_OUTPUT_MODE=widgets.Text(value=\"overwrite\",style=style)\n",
    "display(JDBCTOJDBC_OUTPUT_MODE)\n",
    "\n",
    "display(widgets.Label(\"POSTGRES Output Batch Size\"))\n",
    "JDBCTOJDBC_OUTPUT_BATCH_SIZE=widgets.Text(value=\"1000\",style=style)\n",
    "display(JDBCTOJDBC_OUTPUT_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba335fa7-d46f-4253-bc7f-b0cb5c303592",
   "metadata": {},
   "source": [
    "### Step 3.4 Notebook Configuration Parameters\n",
    "#### Below variables shoulld not be changed unless required\n",
    "#### In case required:\n",
    "\n",
    "* Change disabled=False in the respective widget.Text arguments \n",
    "    * eg. PYMSSQL_DRIVER = widgets.Text(value=\"mssql+pymssql\",description=\"Python MSSQL Driver\",style=style,disabled=False)\n",
    "* Fill in the value in the textbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34123cf3-4ce0-49c6-b7b9-ed40f4fb199f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f571cee56264235aa8f7cb7d04839a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Python MSSQL Driver')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61fe4a9e0f164ed18c78b8ea955d5d37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='mssql+pymssql', disabled=True, style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e9be869efa44797a0b27a108c0da6b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='JDBC MSSQL Driver')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10ceeda1e7974f2d80dd56112405ff54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='com.microsoft.sqlserver.jdbc.SQLServerDriver', disabled=True, style=TextStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a77da68e9b34aefb727fd194a9cf62a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='JDBC MSSQL Url')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7140e3894fca448f8874854a8020e71c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='jdbc:sqlserver://10.203.210.5:1433;databaseName=AdvDB;user=sqlserver;password=password123', disabl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab04e5a3e7c3448aaef94df84cad4fb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Dataproc Main Class')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b04d9220ccc4d46ad838ea5d8bad6ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='com.google.cloud.dataproc.templates.main.DataProcTemplate', disabled=True, style=TextStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53c301ca35634a29ad25d82764a22351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Working Directory')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c965af7321334cc588bf37ceb003f66a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='/home/jupyter/dataproc-templates/python/', disabled=True, style=TextStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b39f1acf3cf473d841e3a88866f6f83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='JDBC POSTGRES Driver')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7050d35caf7942e89683cb975161cd58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='org.postgresql.Driver', disabled=True, style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3db59a8a76424204b9c99cf4c1d367eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='JDBC POSTGRES Url')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d14371bed6b40dbb2ac4fb84742403a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='jdbc:postgresql://10.203.211.3:5432/postadvdb?user=postgres&password=password123', disabled=True, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "905c07872aea4ebf8f314239f8a26267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Dataproc Jar Name')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eaeb4a697874a7489dbc941fd23bb10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='dataproc-templates-1.0-SNAPSHOT.jar', disabled=True, style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c774d804ecc4f2aa14103fbc90156b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Dataproc Package Egg File')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47c8fd476ed04ff083b15ecc28d61220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='dist/dataproc_templates_distribution.egg', disabled=True, style=TextStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(widgets.Label(\"Python MSSQL Driver\"))\n",
    "PYMSSQL_DRIVER = widgets.Text(value=\"mssql+pymssql\",style=style,disabled=True)\n",
    "display(PYMSSQL_DRIVER)\n",
    "\n",
    "display(widgets.Label(\"JDBC MSSQL Driver\"))\n",
    "JDBC_INPUT_DRIVER = widgets.Text(value=\"com.microsoft.sqlserver.jdbc.SQLServerDriver\",style=style,disabled=True)\n",
    "display(JDBC_INPUT_DRIVER)\n",
    "\n",
    "display(widgets.Label(\"JDBC MSSQL Url\"))\n",
    "JDBC_INPUT_URL = widgets.Text(value=\"jdbc:sqlserver://{0}:{1};databaseName={2};user={3};password={4}\".format(MSSQL_HOST.value,MSSQL_PORT.value,MSSQL_DATABASE.value,MSSQL_USERNAME.value,MSSQL_PASSWORD.value),style=style,disabled=True)\n",
    "display(JDBC_INPUT_URL)\n",
    "\n",
    "display(widgets.Label(\"Dataproc Main Class\"))\n",
    "MAIN_CLASS = widgets.Text(value=\"com.google.cloud.dataproc.templates.main.DataProcTemplate\",style=style,disabled=True)\n",
    "display(MAIN_CLASS)\n",
    "\n",
    "display(widgets.Label(\"Working Directory\"))\n",
    "WORKING_DIRECTORY = widgets.Text(value=\"/home/jupyter/dataproc-templates/python/\",style=style,disabled=True)\n",
    "display(WORKING_DIRECTORY)\n",
    "\n",
    "display(widgets.Label(\"JDBC POSTGRES Driver\"))\n",
    "JDBC_OUTPUT_DRIVER = widgets.Text(value=\"org.postgresql.Driver\",style=style,disabled=True)\n",
    "display(JDBC_OUTPUT_DRIVER)\n",
    "\n",
    "display(widgets.Label(\"JDBC POSTGRES Url\"))\n",
    "JDBC_OUTPUT_URL = widgets.Text(value=\"jdbc:postgresql://{0}:{1}/{2}?user={3}&password={4}\".format(POSTGRES_HOST.value,POSTGRES_PORT.value,POSTGRES_DATABASE.value,POSTGRES_USERNAME.value,POSTGRES_PASSWORD.value),style=style,disabled=True)\n",
    "display(JDBC_OUTPUT_URL)\n",
    "\n",
    "display(widgets.Label(\"Dataproc Jar Name\"))\n",
    "JAR_FILE = widgets.Text(value=\"dataproc-templates-1.0-SNAPSHOT.jar\",style=style,disabled=True)\n",
    "display(JAR_FILE)\n",
    "\n",
    "display(widgets.Label(\"Dataproc Package Egg File\"))\n",
    "PACKAGE_EGG_FILE = widgets.Text(value = \"dist/dataproc_templates_distribution.egg\",style=style,disabled=True)\n",
    "display(PACKAGE_EGG_FILE)\n",
    "\n",
    "PIPELINE_ROOT = GCS_STAGING_LOCATION.value + \"/pipeline_root/dataproc_pyspark\"\n",
    "MAIN_PYTHON_FILE = GCS_STAGING_LOCATION.value + \"/main.py\"\n",
    "PYTHON_FILE_URIS = [GCS_STAGING_LOCATION.value + \"/dist/dataproc_templates_distribution.egg\"]\n",
    "\n",
    "# Do not change this parameter unless you want to refer below JARS from new location\n",
    "JARS = [GCS_STAGING_LOCATION.value + \"/jars/mssql-jdbc-6.4.0.jre8.jar\", GCS_STAGING_LOCATION.value + \"/jars/postgresql-42.2.6.jar\", GCS_STAGING_LOCATION.value + \"/\" + JAR_FILE.value]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca6ce4f-cfd2-4726-8e80-9cb059a05550",
   "metadata": {},
   "source": [
    "## Step 4: Generate MSSQL Table List\n",
    "This step creates list of tables for migration. If MSSQLTABLE_LIST is kept empty all the tables in the MSSQL_DATABASE are listed for migration otherwise the provided list is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "3a7a89ee-7500-4ad1-b444-0971b40599f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected to database\n",
      "Total Tables =  91\n",
      "list of tables for migration :\n",
      "['HumanResources.EmployeePayHistory', 'Sales.SalesOrderHeaderSalesReason', 'Sales.SalesPerson', 'Production.Illustration', 'HumanResources.JobCandidate', 'Production.Location', 'Person.Password', 'Sales.SalesPersonQuotaHistory', 'Person.Person', 'Sales.SalesReason', 'Sales.SalesTaxRate', 'Sales.PersonCreditCard', 'Person.vAdditionalContactInfo', 'Person.PersonPhone', 'HumanResources.vEmployee', 'Sales.SalesTerritory', 'HumanResources.vEmployeeDepartment', 'Person.PhoneNumberType', 'HumanResources.vEmployeeDepartmentHistory', 'Sales.vIndividualCustomer', 'Production.Product', 'Sales.vPersonDemographics', 'HumanResources.vJobCandidate', 'HumanResources.vJobCandidateEmployment', 'HumanResources.vJobCandidateEducation', 'Production.vProductAndDescription', 'Production.vProductModelCatalogDescription', 'Production.vProductModelInstructions', 'Sales.vSalesPerson', 'Sales.SalesTerritoryHistory', 'Sales.vSalesPersonSalesByFiscalYears', 'Person.vStateProvinceCountryRegion', 'Sales.vStoreWithDemographics', 'Sales.vStoreWithContacts', 'Production.ScrapReason', 'Sales.vStoreWithAddresses', 'Purchasing.vVendorWithContacts', 'HumanResources.Shift', 'Purchasing.vVendorWithAddresses', 'Production.ProductCategory', 'Purchasing.ShipMethod', 'Production.ProductCostHistory', 'Production.ProductDescription', 'Sales.ShoppingCartItem', 'Production.ProductDocument', 'dbo.DatabaseLog', 'Production.ProductInventory', 'Sales.SpecialOffer', 'dbo.ErrorLog', 'Production.ProductListPriceHistory', 'Person.Address', 'Sales.SpecialOfferProduct', 'Production.ProductModel', 'Person.AddressType', 'Person.StateProvince', 'Production.ProductModelIllustration', 'dbo.AWBuildVersion', 'Production.ProductModelProductDescriptionCulture', 'Production.BillOfMaterials', 'Sales.Store', 'Production.ProductPhoto', 'Production.ProductProductPhoto', 'Production.TransactionHistory', 'Production.ProductReview', 'Person.BusinessEntity', 'Production.TransactionHistoryArchive', 'Production.ProductSubcategory', 'Person.BusinessEntityAddress', 'Purchasing.ProductVendor', 'Person.BusinessEntityContact', 'Production.UnitMeasure', 'Purchasing.Vendor', 'Person.ContactType', 'Sales.CountryRegionCurrency', 'Person.CountryRegion', 'Production.WorkOrder', 'Purchasing.PurchaseOrderDetail', 'Sales.CreditCard', 'Production.Culture', 'Production.WorkOrderRouting', 'Sales.Currency', 'Purchasing.PurchaseOrderHeader', 'Sales.CurrencyRate', 'Sales.Customer', 'HumanResources.Department', 'Production.Document', 'Sales.SalesOrderDetail', 'Person.EmailAddress', 'HumanResources.Employee', 'Sales.SalesOrderHeader', 'HumanResources.EmployeeDepartmentHistory']\n"
     ]
    }
   ],
   "source": [
    "SQLTABLE_LIST=[]\n",
    "SQLTABLE_LIST=MSSQLTABLE_LIST.value.strip().split(\",\")\n",
    "if len(SQLTABLE_LIST) == 0 or SQLTABLE_LIST[0]=='':\n",
    "    SQLTABLE_LIST.pop()\n",
    "    DB = sqlalchemy.create_engine(\n",
    "            sqlalchemy.engine.url.URL.create(\n",
    "                drivername=PYMSSQL_DRIVER.value,\n",
    "                username=MSSQL_USERNAME.value,\n",
    "                password=MSSQL_PASSWORD.value,\n",
    "                database=MSSQL_DATABASE.value,\n",
    "                host=MSSQL_HOST.value,\n",
    "                port=MSSQL_PORT.value\n",
    "              )\n",
    "            )\n",
    "    with DB.connect() as conn:\n",
    "        print(\"connected to database\")\n",
    "        results = DB.execute('select TABLE_SCHEMA,TABLE_NAME from INFORMATION_SCHEMA.Tables').fetchall()\n",
    "        print(\"Total Tables = \", len(results))\n",
    "        for row in results:\n",
    "            SQLTABLE_LIST.append(row[0]+\".\"+row[1])\n",
    "\n",
    "print(\"list of tables for migration :\")\n",
    "print(SQLTABLE_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9304c2-e713-482a-aa9e-ddc97578b98b",
   "metadata": {},
   "source": [
    "## Step 5: Get Primary Keys for partition the tables\n",
    "This step fetches primary key from MSSQL_DATABASE for the tables listed for migration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "3ab28c89-4c2f-486e-9d7b-edfc89f0d5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_TABLE_PRIMARY_KEYS = {}\n",
    "DB = sqlalchemy.create_engine(\n",
    "            sqlalchemy.engine.url.URL.create(\n",
    "                drivername=PYMSSQL_DRIVER.value,\n",
    "                username=MSSQL_USERNAME.value,\n",
    "                password=MSSQL_PASSWORD.value,\n",
    "                database=MSSQL_DATABASE.value,\n",
    "                host=MSSQL_HOST.value,\n",
    "                port=MSSQL_PORT.value\n",
    "              )\n",
    "            )\n",
    "with DB.connect() as conn:\n",
    "    for table in SQLTABLE_LIST:\n",
    "        primary_keys = []\n",
    "        results = DB.execute(\"SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.TABLE_CONSTRAINTS T JOIN INFORMATION_SCHEMA.KEY_COLUMN_USAGE K ON K.CONSTRAINT_NAME=T.CONSTRAINT_NAME  WHERE  K.TABLE_NAME='{0}'  AND K.TABLE_SCHEMA='{1}' AND T.CONSTRAINT_TYPE='PRIMARY KEY';\".format(table.split(\".\")[1],table.split(\".\")[0])).fetchall()\n",
    "        for row in results:\n",
    "            primary_keys.append(row[0])\n",
    "        if primary_keys:\n",
    "            SQL_TABLE_PRIMARY_KEYS[table] = \",\".join(primary_keys)\n",
    "        else:\n",
    "            SQL_TABLE_PRIMARY_KEYS[table] = \"\"\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "59679f52-0774-4cd6-8822-b6e80fb08224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are identified primary keys for migrating mssql table to postgres:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table</th>\n",
       "      <th>primary_keys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HumanResources.EmployeePayHistory</td>\n",
       "      <td>BusinessEntityID,RateChangeDate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sales.SalesOrderHeaderSalesReason</td>\n",
       "      <td>SalesOrderID,SalesReasonID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sales.SalesPerson</td>\n",
       "      <td>BusinessEntityID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Production.Illustration</td>\n",
       "      <td>IllustrationID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HumanResources.JobCandidate</td>\n",
       "      <td>JobCandidateID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Sales.SalesOrderDetail</td>\n",
       "      <td>SalesOrderDetailID,SalesOrderID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Person.EmailAddress</td>\n",
       "      <td>BusinessEntityID,EmailAddressID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>HumanResources.Employee</td>\n",
       "      <td>BusinessEntityID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Sales.SalesOrderHeader</td>\n",
       "      <td>SalesOrderID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>HumanResources.EmployeeDepartmentHistory</td>\n",
       "      <td>BusinessEntityID,DepartmentID,ShiftID,StartDate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       table  \\\n",
       "0          HumanResources.EmployeePayHistory   \n",
       "1          Sales.SalesOrderHeaderSalesReason   \n",
       "2                          Sales.SalesPerson   \n",
       "3                    Production.Illustration   \n",
       "4                HumanResources.JobCandidate   \n",
       "..                                       ...   \n",
       "86                    Sales.SalesOrderDetail   \n",
       "87                       Person.EmailAddress   \n",
       "88                   HumanResources.Employee   \n",
       "89                    Sales.SalesOrderHeader   \n",
       "90  HumanResources.EmployeeDepartmentHistory   \n",
       "\n",
       "                                       primary_keys  \n",
       "0                   BusinessEntityID,RateChangeDate  \n",
       "1                        SalesOrderID,SalesReasonID  \n",
       "2                                  BusinessEntityID  \n",
       "3                                    IllustrationID  \n",
       "4                                    JobCandidateID  \n",
       "..                                              ...  \n",
       "86                  SalesOrderDetailID,SalesOrderID  \n",
       "87                  BusinessEntityID,EmailAddressID  \n",
       "88                                 BusinessEntityID  \n",
       "89                                     SalesOrderID  \n",
       "90  BusinessEntityID,DepartmentID,ShiftID,StartDate  \n",
       "\n",
       "[91 rows x 2 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkDF = pd.DataFrame({\"table\" : SQLTABLE_LIST, \"primary_keys\": list(SQL_TABLE_PRIMARY_KEYS.values())})\n",
    "print(\"Below are identified primary keys for migrating mssql table to postgres:\")\n",
    "pkDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363d46ea-d3a7-4e52-b527-21bee93fd305",
   "metadata": {},
   "source": [
    "## Step 6: Create JAR files and Upload to GCS\n",
    "#### Run Step 6 one time for each new notebook instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b3742b9a-143d-49fc-b43c-e56179c7f0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/dataproc-templates/python\n"
     ]
    }
   ],
   "source": [
    "%cd $WORKING_DIRECTORY.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4087b4b-c5be-407d-b2bd-e5d6da5a0222",
   "metadata": {},
   "source": [
    "#### Get JDBC Connector jars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a0fa7572-0a4b-49c7-9359-cf3ce4514b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2022-09-22 13:16:01--  https://jdbc.postgresql.org/download/postgresql-42.2.6.jar\n",
      "Resolving jdbc.postgresql.org (jdbc.postgresql.org)... 72.32.157.228, 2001:4800:3e1:1::228\n",
      "Connecting to jdbc.postgresql.org (jdbc.postgresql.org)|72.32.157.228|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 842825 (823K) [application/java-archive]\n",
      "Saving to: ‘postgresql-42.2.6.jar.5’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  6% 1.28M 1s\n",
      "    50K .......... .......... .......... .......... .......... 12% 1.30M 1s\n",
      "   100K .......... .......... .......... .......... .......... 18%  118M 0s\n",
      "   150K .......... .......... .......... .......... .......... 24% 1.29M 0s\n",
      "   200K .......... .......... .......... .......... .......... 30%  187M 0s\n",
      "   250K .......... .......... .......... .......... .......... 36% 56.6M 0s\n",
      "   300K .......... .......... .......... .......... .......... 42% 1.35M 0s\n",
      "   350K .......... .......... .......... .......... .......... 48% 94.7M 0s\n",
      "   400K .......... .......... .......... .......... .......... 54%  125M 0s\n",
      "   450K .......... .......... .......... .......... .......... 60%  111M 0s\n",
      "   500K .......... .......... .......... .......... .......... 66% 83.7M 0s\n",
      "   550K .......... .......... .......... .......... .......... 72% 96.8M 0s\n",
      "   600K .......... .......... .......... .......... .......... 78% 84.9M 0s\n",
      "   650K .......... .......... .......... .......... .......... 85% 47.0M 0s\n",
      "   700K .......... .......... .......... .......... .......... 91% 1.42M 0s\n",
      "   750K .......... .......... .......... .......... .......... 97% 92.8M 0s\n",
      "   800K .......... .......... ...                             100%  192M=0.2s\n",
      "\n",
      "2022-09-22 13:16:02 (4.22 MB/s) - ‘postgresql-42.2.6.jar.5’ saved [842825/842825]\n",
      "\n",
      "--2022-09-22 13:16:02--  https://repo1.maven.org/maven2/com/microsoft/sqlserver/mssql-jdbc/6.4.0.jre8/mssql-jdbc-6.4.0.jre8.jar\n",
      "Resolving repo1.maven.org (repo1.maven.org)... 199.232.192.209, 199.232.196.209\n",
      "Connecting to repo1.maven.org (repo1.maven.org)|199.232.192.209|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 905963 (885K) [application/java-archive]\n",
      "Saving to: ‘mssql-jdbc-6.4.0.jre8.jar.5’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  5% 6.20M 0s\n",
      "    50K .......... .......... .......... .......... .......... 11% 7.19M 0s\n",
      "   100K .......... .......... .......... .......... .......... 16% 25.9M 0s\n",
      "   150K .......... .......... .......... .......... .......... 22% 39.3M 0s\n",
      "   200K .......... .......... .......... .......... .......... 28% 11.4M 0s\n",
      "   250K .......... .......... .......... .......... .......... 33% 26.1M 0s\n",
      "   300K .......... .......... .......... .......... .......... 39% 96.0M 0s\n",
      "   350K .......... .......... .......... .......... .......... 45%  164M 0s\n",
      "   400K .......... .......... .......... .......... .......... 50% 46.8M 0s\n",
      "   450K .......... .......... .......... .......... .......... 56% 12.3M 0s\n",
      "   500K .......... .......... .......... .......... .......... 62%  115M 0s\n",
      "   550K .......... .......... .......... .......... .......... 67% 44.6M 0s\n",
      "   600K .......... .......... .......... .......... .......... 73%  192M 0s\n",
      "   650K .......... .......... .......... .......... .......... 79%  108M 0s\n",
      "   700K .......... .......... .......... .......... .......... 84%  129M 0s\n",
      "   750K .......... .......... .......... .......... .......... 90%  121M 0s\n",
      "   800K .......... .......... .......... .......... .......... 96%  192M 0s\n",
      "   850K .......... .......... .......... ....                 100% 61.9M=0.03s\n",
      "\n",
      "2022-09-22 13:16:02 (25.7 MB/s) - ‘mssql-jdbc-6.4.0.jre8.jar.5’ saved [905963/905963]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wget https://jdbc.postgresql.org/download/postgresql-42.2.6.jar\n",
    "wget https://repo1.maven.org/maven2/com/microsoft/sqlserver/mssql-jdbc/6.4.0.jre8/mssql-jdbc-6.4.0.jre8.jar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e141fde-4e48-4953-833b-176e255037c9",
   "metadata": {},
   "source": [
    "#### Build Dataproc Templates python package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "6f399004-26bf-480a-9640-5cfb97994f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running bdist_egg\n",
      "running egg_info\n",
      "writing dataproc_templates.egg-info/PKG-INFO\n",
      "writing dependency_links to dataproc_templates.egg-info/dependency_links.txt\n",
      "writing requirements to dataproc_templates.egg-info/requires.txt\n",
      "writing top-level names to dataproc_templates.egg-info/top_level.txt\n",
      "reading manifest file 'dataproc_templates.egg-info/SOURCES.txt'\n",
      "writing manifest file 'dataproc_templates.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "/opt/conda/lib/python3.7/site-packages/setuptools/command/install.py:37: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  setuptools.SetuptoolsDeprecationWarning,\n",
      "running install_lib\n",
      "running build_py\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/dataproc_templates\n",
      "copying build/lib/dataproc_templates/__init__.py -> build/bdist.linux-x86_64/egg/dataproc_templates\n",
      "copying build/lib/dataproc_templates/template_name.py -> build/bdist.linux-x86_64/egg/dataproc_templates\n",
      "creating build/bdist.linux-x86_64/egg/dataproc_templates/mongo\n",
      "copying build/lib/dataproc_templates/mongo/__init__.py -> build/bdist.linux-x86_64/egg/dataproc_templates/mongo\n",
      "copying build/lib/dataproc_templates/mongo/mongo_to_gcs.py -> build/bdist.linux-x86_64/egg/dataproc_templates/mongo\n",
      "creating build/bdist.linux-x86_64/egg/dataproc_templates/util\n",
      "copying build/lib/dataproc_templates/util/template_constants.py -> build/bdist.linux-x86_64/egg/dataproc_templates/util\n",
      "copying build/lib/dataproc_templates/util/__init__.py -> build/bdist.linux-x86_64/egg/dataproc_templates/util\n",
      "copying build/lib/dataproc_templates/util/argument_parsing.py -> build/bdist.linux-x86_64/egg/dataproc_templates/util\n",
      "copying build/lib/dataproc_templates/util/tracking.py -> build/bdist.linux-x86_64/egg/dataproc_templates/util\n",
      "creating build/bdist.linux-x86_64/egg/dataproc_templates/jdbc\n",
      "copying build/lib/dataproc_templates/jdbc/__init__.py -> build/bdist.linux-x86_64/egg/dataproc_templates/jdbc\n",
      "copying build/lib/dataproc_templates/jdbc/jdbc_to_jdbc.py -> build/bdist.linux-x86_64/egg/dataproc_templates/jdbc\n",
      "copying build/lib/dataproc_templates/jdbc/jdbc_to_gcs.py -> build/bdist.linux-x86_64/egg/dataproc_templates/jdbc\n",
      "creating build/bdist.linux-x86_64/egg/dataproc_templates/bigquery\n",
      "copying build/lib/dataproc_templates/bigquery/__init__.py -> build/bdist.linux-x86_64/egg/dataproc_templates/bigquery\n",
      "copying build/lib/dataproc_templates/bigquery/bigquery_to_gcs.py -> build/bdist.linux-x86_64/egg/dataproc_templates/bigquery\n",
      "copying build/lib/dataproc_templates/base_template.py -> build/bdist.linux-x86_64/egg/dataproc_templates\n",
      "creating build/bdist.linux-x86_64/egg/dataproc_templates/gcs\n",
      "copying build/lib/dataproc_templates/gcs/__init__.py -> build/bdist.linux-x86_64/egg/dataproc_templates/gcs\n",
      "copying build/lib/dataproc_templates/gcs/gcs_to_jdbc.py -> build/bdist.linux-x86_64/egg/dataproc_templates/gcs\n",
      "copying build/lib/dataproc_templates/gcs/gcs_to_mongo.py -> build/bdist.linux-x86_64/egg/dataproc_templates/gcs\n",
      "copying build/lib/dataproc_templates/gcs/text_to_bigquery.py -> build/bdist.linux-x86_64/egg/dataproc_templates/gcs\n",
      "copying build/lib/dataproc_templates/gcs/gcs_to_gcs.py -> build/bdist.linux-x86_64/egg/dataproc_templates/gcs\n",
      "copying build/lib/dataproc_templates/gcs/gcs_to_bigquery.py -> build/bdist.linux-x86_64/egg/dataproc_templates/gcs\n",
      "copying build/lib/dataproc_templates/gcs/gcs_to_bigtable.py -> build/bdist.linux-x86_64/egg/dataproc_templates/gcs\n",
      "creating build/bdist.linux-x86_64/egg/dataproc_templates/hbase\n",
      "copying build/lib/dataproc_templates/hbase/__init__.py -> build/bdist.linux-x86_64/egg/dataproc_templates/hbase\n",
      "copying build/lib/dataproc_templates/hbase/hbase_to_gcs.py -> build/bdist.linux-x86_64/egg/dataproc_templates/hbase\n",
      "creating build/bdist.linux-x86_64/egg/dataproc_templates/hive\n",
      "copying build/lib/dataproc_templates/hive/hive_to_gcs.py -> build/bdist.linux-x86_64/egg/dataproc_templates/hive\n",
      "copying build/lib/dataproc_templates/hive/__init__.py -> build/bdist.linux-x86_64/egg/dataproc_templates/hive\n",
      "copying build/lib/dataproc_templates/hive/hive_to_bigquery.py -> build/bdist.linux-x86_64/egg/dataproc_templates/hive\n",
      "creating build/bdist.linux-x86_64/egg/test\n",
      "creating build/bdist.linux-x86_64/egg/test/mongo\n",
      "copying build/lib/test/mongo/__init__.py -> build/bdist.linux-x86_64/egg/test/mongo\n",
      "copying build/lib/test/mongo/test_mongo_to_gcs.py -> build/bdist.linux-x86_64/egg/test/mongo\n",
      "creating build/bdist.linux-x86_64/egg/test/util\n",
      "copying build/lib/test/util/__init__.py -> build/bdist.linux-x86_64/egg/test/util\n",
      "copying build/lib/test/util/test_argument_parsing.py -> build/bdist.linux-x86_64/egg/test/util\n",
      "creating build/bdist.linux-x86_64/egg/test/jdbc\n",
      "copying build/lib/test/jdbc/__init__.py -> build/bdist.linux-x86_64/egg/test/jdbc\n",
      "copying build/lib/test/jdbc/test_jdbc_to_jdbc.py -> build/bdist.linux-x86_64/egg/test/jdbc\n",
      "copying build/lib/test/jdbc/test_jdbc_to_gcs.py -> build/bdist.linux-x86_64/egg/test/jdbc\n",
      "creating build/bdist.linux-x86_64/egg/test/bigquery\n",
      "copying build/lib/test/bigquery/__init__.py -> build/bdist.linux-x86_64/egg/test/bigquery\n",
      "copying build/lib/test/bigquery/test_bigquery_to_gcs.py -> build/bdist.linux-x86_64/egg/test/bigquery\n",
      "creating build/bdist.linux-x86_64/egg/test/gcs\n",
      "copying build/lib/test/gcs/__init__.py -> build/bdist.linux-x86_64/egg/test/gcs\n",
      "copying build/lib/test/gcs/test_gcs_to_gcs.py -> build/bdist.linux-x86_64/egg/test/gcs\n",
      "copying build/lib/test/gcs/test_gcs_to_jdbc.py -> build/bdist.linux-x86_64/egg/test/gcs\n",
      "copying build/lib/test/gcs/test_text_to_bigquery.py -> build/bdist.linux-x86_64/egg/test/gcs\n",
      "copying build/lib/test/gcs/test_gcs_to_bigquery.py -> build/bdist.linux-x86_64/egg/test/gcs\n",
      "copying build/lib/test/gcs/test_gcs_to_bigtable.py -> build/bdist.linux-x86_64/egg/test/gcs\n",
      "copying build/lib/test/gcs/test_gcs_to_mongo.py -> build/bdist.linux-x86_64/egg/test/gcs\n",
      "creating build/bdist.linux-x86_64/egg/test/hbase\n",
      "copying build/lib/test/hbase/__init__.py -> build/bdist.linux-x86_64/egg/test/hbase\n",
      "copying build/lib/test/hbase/test_hbase_to_gcs.py -> build/bdist.linux-x86_64/egg/test/hbase\n",
      "creating build/bdist.linux-x86_64/egg/test/hive\n",
      "copying build/lib/test/hive/test_hive_to_bigquery.py -> build/bdist.linux-x86_64/egg/test/hive\n",
      "copying build/lib/test/hive/__init__.py -> build/bdist.linux-x86_64/egg/test/hive\n",
      "copying build/lib/test/hive/test_hive_to_gcs.py -> build/bdist.linux-x86_64/egg/test/hive\n",
      "byte-compiling build/bdist.linux-x86_64/egg/dataproc_templates/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/dataproc_templates/template_name.py to template_name.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/dataproc_templates/mongo/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/dataproc_templates/mongo/mongo_to_gcs.py to mongo_to_gcs.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/dataproc_templates/util/template_constants.py to template_constants.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/dataproc_templates/util/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/dataproc_templates/util/argument_parsing.py to argument_parsing.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/dataproc_templates/util/tracking.py to tracking.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/dataproc_templates/jdbc/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/dataproc_templates/jdbc/jdbc_to_jdbc.py to jdbc_to_jdbc.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/dataproc_templates/jdbc/jdbc_to_gcs.py to jdbc_to_gcs.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/dataproc_templates/bigquery/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/dataproc_templates/bigquery/bigquery_to_gcs.py to bigquery_to_gcs.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/dataproc_templates/base_template.py to base_template.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/dataproc_templates/gcs/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/dataproc_templates/gcs/gcs_to_jdbc.py to gcs_to_jdbc.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/dataproc_templates/gcs/gcs_to_mongo.py to gcs_to_mongo.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/dataproc_templates/gcs/text_to_bigquery.py to text_to_bigquery.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/dataproc_templates/gcs/gcs_to_gcs.py to gcs_to_gcs.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/dataproc_templates/gcs/gcs_to_bigquery.py to gcs_to_bigquery.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/dataproc_templates/gcs/gcs_to_bigtable.py to gcs_to_bigtable.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/dataproc_templates/hbase/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/dataproc_templates/hbase/hbase_to_gcs.py to hbase_to_gcs.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/dataproc_templates/hive/hive_to_gcs.py to hive_to_gcs.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/dataproc_templates/hive/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/dataproc_templates/hive/hive_to_bigquery.py to hive_to_bigquery.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/test/mongo/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/test/mongo/test_mongo_to_gcs.py to test_mongo_to_gcs.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/test/util/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/test/util/test_argument_parsing.py to test_argument_parsing.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/test/jdbc/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/test/jdbc/test_jdbc_to_jdbc.py to test_jdbc_to_jdbc.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/test/jdbc/test_jdbc_to_gcs.py to test_jdbc_to_gcs.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/test/bigquery/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/test/bigquery/test_bigquery_to_gcs.py to test_bigquery_to_gcs.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/test/gcs/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/test/gcs/test_gcs_to_gcs.py to test_gcs_to_gcs.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/test/gcs/test_gcs_to_jdbc.py to test_gcs_to_jdbc.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/test/gcs/test_text_to_bigquery.py to test_text_to_bigquery.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/test/gcs/test_gcs_to_bigquery.py to test_gcs_to_bigquery.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/test/gcs/test_gcs_to_bigtable.py to test_gcs_to_bigtable.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/test/gcs/test_gcs_to_mongo.py to test_gcs_to_mongo.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/test/hbase/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/test/hbase/test_hbase_to_gcs.py to test_hbase_to_gcs.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/test/hive/test_hive_to_bigquery.py to test_hive_to_bigquery.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/test/hive/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/test/hive/test_hive_to_gcs.py to test_hive_to_gcs.cpython-37.pyc\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying dataproc_templates.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying dataproc_templates.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying dataproc_templates.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying dataproc_templates.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying dataproc_templates.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "creating 'dist/dataproc_templates-0.0.1-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Will rename output .egg file from dist/dataproc_templates-0.0.1-py3.7.egg to dist/dataproc_templates_distribution.egg\n"
     ]
    }
   ],
   "source": [
    "! python ./setup.py bdist_egg --output=$PACKAGE_EGG_FILE.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bea938a-1951-44d4-a18b-063b9d7c8bd4",
   "metadata": {},
   "source": [
    "#### Copying JAR files to GCS_STAGING_LOCATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "33dd85ce-46f6-4b35-8997-2189cf1b2eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://main.py [Content-Type=text/x-python]...\n",
      "/ [1 files][  4.2 KiB/  4.2 KiB]                                                \n",
      "Operation completed over 1 objects/4.2 KiB.                                      \n",
      "Copying file://dist/dataproc_templates_distribution.egg [Content-Type=application/octet-stream]...\n",
      "/ [1 files][114.0 KiB/114.0 KiB]                                                \n",
      "Operation completed over 1 objects/114.0 KiB.                                    \n",
      "Copying file://mssql-jdbc-6.4.0.jre8.jar [Content-Type=application/java-archive]...\n",
      "/ [1 files][884.7 KiB/884.7 KiB]                                                \n",
      "Operation completed over 1 objects/884.7 KiB.                                    \n",
      "Copying file://postgresql-42.2.6.jar [Content-Type=application/java-archive]...\n",
      "/ [1 files][823.1 KiB/823.1 KiB]                                                \n",
      "Operation completed over 1 objects/823.1 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "! gsutil cp main.py $GCS_STAGING_LOCATION.value/\n",
    "! gsutil cp -r $PACKAGE_EGG_FILE.value $GCS_STAGING_LOCATION.value/\n",
    "! gsutil cp mssql-jdbc-6.4.0.jre8.jar $GCS_STAGING_LOCATION.value/jars/mssql-jdbc-6.4.0.jre8.jar\n",
    "! gsutil cp postgresql-42.2.6.jar $GCS_STAGING_LOCATION.value/jars/postgresql-42.2.6.jar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf52c73c-ad16-4932-a421-349f5f718df2",
   "metadata": {},
   "source": [
    "## Step 7: Calculate Parallel Jobs for MSSQL to POSTGRES\n",
    "This step uses MAX_PARALLELISM parameter to calculate number of parallel jobs to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f8bc06aa-298b-4d1f-9822-62264371a681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of tables for execution : \n",
      "[['HumanResources.EmployeePayHistory', 'Sales.SalesOrderHeaderSalesReason', 'Sales.SalesPerson', 'Production.Illustration', 'HumanResources.JobCandidate', 'Production.Location', 'Person.Password', 'Sales.SalesPersonQuotaHistory', 'Person.Person', 'Sales.SalesReason'], ['Sales.SalesTaxRate', 'Sales.PersonCreditCard', 'Person.vAdditionalContactInfo', 'Person.PersonPhone', 'HumanResources.vEmployee', 'Sales.SalesTerritory', 'HumanResources.vEmployeeDepartment', 'Person.PhoneNumberType', 'HumanResources.vEmployeeDepartmentHistory', 'Sales.vIndividualCustomer'], ['Production.Product', 'Sales.vPersonDemographics', 'HumanResources.vJobCandidate', 'HumanResources.vJobCandidateEmployment', 'HumanResources.vJobCandidateEducation', 'Production.vProductAndDescription', 'Production.vProductModelCatalogDescription', 'Production.vProductModelInstructions', 'Sales.vSalesPerson', 'Sales.SalesTerritoryHistory'], ['Sales.vSalesPersonSalesByFiscalYears', 'Person.vStateProvinceCountryRegion', 'Sales.vStoreWithDemographics', 'Sales.vStoreWithContacts', 'Production.ScrapReason', 'Sales.vStoreWithAddresses', 'Purchasing.vVendorWithContacts', 'HumanResources.Shift', 'Purchasing.vVendorWithAddresses', 'Production.ProductCategory'], ['Purchasing.ShipMethod', 'Production.ProductCostHistory', 'Production.ProductDescription', 'Sales.ShoppingCartItem', 'Production.ProductDocument', 'dbo.DatabaseLog', 'Production.ProductInventory', 'Sales.SpecialOffer', 'dbo.ErrorLog', 'Production.ProductListPriceHistory'], ['Person.Address', 'Sales.SpecialOfferProduct', 'Production.ProductModel', 'Person.AddressType', 'Person.StateProvince', 'Production.ProductModelIllustration', 'dbo.AWBuildVersion', 'Production.ProductModelProductDescriptionCulture', 'Production.BillOfMaterials', 'Sales.Store'], ['Production.ProductPhoto', 'Production.ProductProductPhoto', 'Production.TransactionHistory', 'Production.ProductReview', 'Person.BusinessEntity', 'Production.TransactionHistoryArchive', 'Production.ProductSubcategory', 'Person.BusinessEntityAddress', 'Purchasing.ProductVendor', 'Person.BusinessEntityContact'], ['Production.UnitMeasure', 'Purchasing.Vendor', 'Person.ContactType', 'Sales.CountryRegionCurrency', 'Person.CountryRegion', 'Production.WorkOrder', 'Purchasing.PurchaseOrderDetail', 'Sales.CreditCard', 'Production.Culture', 'Production.WorkOrderRouting'], ['Sales.Currency', 'Purchasing.PurchaseOrderHeader', 'Sales.CurrencyRate', 'Sales.Customer', 'HumanResources.Department', 'Production.Document', 'Sales.SalesOrderDetail', 'Person.EmailAddress', 'HumanResources.Employee', 'Sales.SalesOrderHeader'], ['HumanResources.EmployeeDepartmentHistory']]\n"
     ]
    }
   ],
   "source": [
    "COMPLETE_LIST = copy.deepcopy(SQLTABLE_LIST)\n",
    "PARALLEL_JOBS = len(SQLTABLE_LIST)//MAX_PARALLELISM.value\n",
    "JOB_LIST = []\n",
    "while len(COMPLETE_LIST) > 0:\n",
    "    SUB_LIST = []\n",
    "    for i in range(MAX_PARALLELISM.value):\n",
    "        if len(COMPLETE_LIST)>0 :\n",
    "            SUB_LIST.append(COMPLETE_LIST[0])\n",
    "            COMPLETE_LIST.pop(0)\n",
    "        else:\n",
    "            break\n",
    "    JOB_LIST.append(SUB_LIST)\n",
    "print(\"list of tables for execution : \")\n",
    "print(JOB_LIST)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fd6c0e-9128-4981-916e-f774e40f9120",
   "metadata": {},
   "source": [
    "## Step 8: Get Row Count of Tables and identify Partition Columns \n",
    "#### This step uses PARTITION_THRESHOLD parameter and any table having rows greater than PARTITION_THRESHOLD will be partitioned based on Primary Keys\n",
    "#### Get Primary keys for all tables to be migrated and find an integer column to partition on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "bfa2bacc-b3b0-43f0-8825-8744010a25b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48439bdda2544348b45d74edeb4a0925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Maximum Row Count Threshold for a Table')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c2b0d0bbd5547fdb791e8715eda5867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='10000', style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(widgets.Label(\"Maximum Row Count Threshold for a Table\"))\n",
    "PARTITION_THRESHOLD = widgets.Text(value=\"10000\",style=style)\n",
    "display(PARTITION_THRESHOLD)\n",
    "\n",
    "CHECK_PARTITION_COLUMN_LIST={}\n",
    "mssql_to_postgres_jobs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "f9725435-79c2-4b40-9aa7-e64e7440fb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Sales.SalesOrderHeaderSalesReason': 'SalesReasonID', 'Person.Password': 'BusinessEntityID', 'Person.Person': 'BusinessEntityID', 'Sales.PersonCreditCard': 'CreditCardID', 'Person.PersonPhone': 'PhoneNumberTypeID', 'Person.Address': 'AddressID', 'Production.TransactionHistory': 'TransactionID', 'Person.BusinessEntity': 'BusinessEntityID', 'Production.TransactionHistoryArchive': 'TransactionID', 'Person.BusinessEntityAddress': 'BusinessEntityID', 'Production.WorkOrder': 'WorkOrderID', 'Sales.CreditCard': 'CreditCardID', 'Production.WorkOrderRouting': 'WorkOrderID', 'Sales.CurrencyRate': 'CurrencyRateID', 'Sales.Customer': 'CustomerID', 'Sales.SalesOrderDetail': 'SalesOrderID', 'Person.EmailAddress': 'EmailAddressID', 'Sales.SalesOrderHeader': 'SalesOrderID'}\n"
     ]
    }
   ],
   "source": [
    "with DB.connect() as conn:\n",
    "    for table in SQLTABLE_LIST:\n",
    "        results = DB.execute(\"SELECT count(1) FROM {}\".format(table)).fetchall()\n",
    "        if results[0][0]>int(PARTITION_THRESHOLD.value) and len(SQL_TABLE_PRIMARY_KEYS.get(table).split(\",\")[0])>0:\n",
    "            column_list=SQL_TABLE_PRIMARY_KEYS.get(table).split(\",\")\n",
    "            for column in column_list:\n",
    "                results_datatype = DB.execute(\"SELECT DATA_TYPE FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_SCHEMA = '{0}' AND TABLE_NAME   = '{1}' AND COLUMN_NAME  = '{2}'\".format(table.split(\".\")[0],table.split(\".\")[1],column)).fetchall()      \n",
    "                if results_datatype[0][0]==\"int\":\n",
    "                    CHECK_PARTITION_COLUMN_LIST[table]=column\n",
    "                \n",
    "                \n",
    "print(CHECK_PARTITION_COLUMN_LIST)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae5f3ed-8ba4-4801-bb31-296221d64578",
   "metadata": {},
   "source": [
    "## Step 9:Create Source Schemas in POSTGRES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "ad52bc86-1c77-4138-ab58-f849226b4137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "postgresDB = psycopg2.connect(\n",
    "                user=POSTGRES_USERNAME.value,\n",
    "                password=POSTGRES_PASSWORD.value,\n",
    "                dbname=POSTGRES_DATABASE.value,\n",
    "                host=POSTGRES_HOST.value,\n",
    "                port=POSTGRES_PORT.value\n",
    "            )\n",
    "postgresDB.autocommit = True\n",
    "conn=postgresDB.cursor()\n",
    "\n",
    "for table in SQLTABLE_LIST:\n",
    "    conn.execute('''CREATE SCHEMA IF NOT EXISTS {};'''.format(table.split(\".\")[0]))\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fce10a-6d1e-4fd6-b1f6-9175680614dd",
   "metadata": {},
   "source": [
    "## Step 10: Execute Pipeline to Migrate tables from MSSQL to POSTGRES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "37abf9cd-d4df-4760-8dda-351ede03bf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def migrate_mssql_to_postgres(EXECUTION_LIST):\n",
    "    EXECUTION_LIST = EXECUTION_LIST\n",
    "    aiplatform.init(project=PROJECT.value,staging_bucket=GCS_STAGING_LOCATION.value)\n",
    "    \n",
    "    @dsl.pipeline(\n",
    "        name=\"python-mssql-to-postgres-pyspark\",\n",
    "        description=\"Pipeline to get data from mssql to postgres\",\n",
    "    )\n",
    "    \n",
    "    def pipeline(\n",
    "        PROJECT_ID: str = PROJECT.value,\n",
    "        LOCATION: str = REGION.value,\n",
    "        MAIN_PYTHON_CLASS: str = MAIN_PYTHON_FILE,\n",
    "        PYTHON_FILE_URIS: list = PYTHON_FILE_URIS,\n",
    "        JAR_FILE_URIS: list = JARS,\n",
    "        SUBNETWORK_URI: str = SUBNET.value\n",
    "        ):\n",
    "        for table in EXECUTION_LIST:\n",
    "            BATCH_ID = \"mssqltopostgres-{}\".format(datetime.now().strftime(\"%s\"))\n",
    "            mssql_to_postgres_jobs.append(BATCH_ID)\n",
    "            \n",
    "            \n",
    "            if table in CHECK_PARTITION_COLUMN_LIST.keys():\n",
    "                TEMPLATE_SPARK_ARGS = [\n",
    "                \"--template=JDBCTOJDBC\",\n",
    "                \"--jdbctojdbc.input.url={}\".format(JDBC_INPUT_URL.value),\n",
    "                \"--jdbctojdbc.input.driver={}\".format(JDBC_INPUT_DRIVER.value),\n",
    "                \"--jdbctojdbc.input.table={}\".format(table),\n",
    "                \"--jdbctojdbc.output.url={}\".format(JDBC_OUTPUT_URL.value),\n",
    "                \"--jdbctojdbc.output.driver={}\".format(JDBC_OUTPUT_DRIVER.value),\n",
    "                \"--jdbctojdbc.output.table={}\".format(table),\n",
    "                \"--jdbctojdbc.input.partitioncolumn={}\".format(CHECK_PARTITION_COLUMN_LIST[table]),\n",
    "                \"--jdbctojdbc.input.lowerbound={}\".format(JDBCTOJDBC_INTPUT_LOWERBOUND.value),\n",
    "                \"--jdbctojdbc.input.upperbound={}\".format(PARTITION_THRESHOLD.value),\n",
    "                \"--jdbctojdbc.numpartitions={}\".format(JDBCTOJDBC_NUMOFPARTITIONS.value),\n",
    "                \"--jdbctojdbc.output.mode={}\".format(JDBCTOJDBC_OUTPUT_MODE.value),\n",
    "                \"--jdbctojdbc.output.batch.size={}\".format(JDBCTOJDBC_OUTPUT_BATCH_SIZE.value)\n",
    "                ]\n",
    "            else:\n",
    "                TEMPLATE_SPARK_ARGS = [\n",
    "                \"--template=JDBCTOJDBC\",\n",
    "                \"--jdbctojdbc.input.url={}\".format(JDBC_INPUT_URL.value),\n",
    "                \"--jdbctojdbc.input.driver={}\".format(JDBC_INPUT_DRIVER.value),\n",
    "                \"--jdbctojdbc.input.table={}\".format(table),\n",
    "                \"--jdbctojdbc.output.url={}\".format(JDBC_OUTPUT_URL.value),\n",
    "                \"--jdbctojdbc.output.driver={}\".format(JDBC_OUTPUT_DRIVER.value),\n",
    "                \"--jdbctojdbc.output.table={}\".format(table),\n",
    "                \"--jdbctojdbc.numpartitions={}\".format(JDBCTOJDBC_NUMOFPARTITIONS.value),\n",
    "                \"--jdbctojdbc.output.mode={}\".format(JDBCTOJDBC_OUTPUT_MODE.value),\n",
    "                \"--jdbctojdbc.output.batch.size={}\".format(JDBCTOJDBC_OUTPUT_BATCH_SIZE.value)\n",
    "                ]\n",
    "            \n",
    "\n",
    "            _ = DataprocPySparkBatchOp(\n",
    "                project=PROJECT_ID,\n",
    "                location=LOCATION,\n",
    "                batch_id=BATCH_ID,\n",
    "                main_python_file_uri=MAIN_PYTHON_CLASS,\n",
    "                jar_file_uris=JAR_FILE_URIS,\n",
    "                python_file_uris=PYTHON_FILE_URIS,\n",
    "                subnetwork_uri=SUBNETWORK_URI,\n",
    "                args=TEMPLATE_SPARK_ARGS\n",
    "                )\n",
    "            time.sleep(3)\n",
    "\n",
    "    compiler.Compiler().compile(pipeline_func=pipeline, package_path=\"pipeline.json\")\n",
    "\n",
    "    pipeline = aiplatform.PipelineJob(\n",
    "            display_name=\"pipeline\",\n",
    "        template_path=\"pipeline.json\",\n",
    "        pipeline_root=PIPELINE_ROOT,\n",
    "        enable_caching=False,\n",
    "        )\n",
    "    pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "18574192-8d4d-43c8-98e5-f3d613c98fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HumanResources.EmployeePayHistory', 'Sales.SalesOrderHeaderSalesReason', 'Sales.SalesPerson', 'Production.Illustration', 'HumanResources.JobCandidate', 'Production.Location', 'Person.Password', 'Sales.SalesPersonQuotaHistory', 'Person.Person', 'Sales.SalesReason']\n",
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922134814\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922134814')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/python-mssql-to-postgres-pyspark-20220922134814?project=617357862702\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922134814 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922134814 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922134814 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922134814 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922134814 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922134814 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922134814\n",
      "['Sales.SalesTaxRate', 'Sales.PersonCreditCard', 'Person.vAdditionalContactInfo', 'Person.PersonPhone', 'HumanResources.vEmployee', 'Sales.SalesTerritory', 'HumanResources.vEmployeeDepartment', 'Person.PhoneNumberType', 'HumanResources.vEmployeeDepartmentHistory', 'Sales.vIndividualCustomer']\n",
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922135705\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922135705')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/python-mssql-to-postgres-pyspark-20220922135705?project=617357862702\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922135705 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922135705 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922135705 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922135705 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922135705 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922135705\n",
      "['Production.Product', 'Sales.vPersonDemographics', 'HumanResources.vJobCandidate', 'HumanResources.vJobCandidateEmployment', 'HumanResources.vJobCandidateEducation', 'Production.vProductAndDescription', 'Production.vProductModelCatalogDescription', 'Production.vProductModelInstructions', 'Sales.vSalesPerson', 'Sales.SalesTerritoryHistory']\n",
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922140219\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922140219')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/python-mssql-to-postgres-pyspark-20220922140219?project=617357862702\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922140219 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922140219 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922140219 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922140219 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922140219 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922140219\n",
      "['Sales.vSalesPersonSalesByFiscalYears', 'Person.vStateProvinceCountryRegion', 'Sales.vStoreWithDemographics', 'Sales.vStoreWithContacts', 'Production.ScrapReason', 'Sales.vStoreWithAddresses', 'Purchasing.vVendorWithContacts', 'HumanResources.Shift', 'Purchasing.vVendorWithAddresses', 'Production.ProductCategory']\n",
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922140728\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922140728')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/python-mssql-to-postgres-pyspark-20220922140728?project=617357862702\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922140728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922140728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922140728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922140728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922140728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922140728\n",
      "['Purchasing.ShipMethod', 'Production.ProductCostHistory', 'Production.ProductDescription', 'Sales.ShoppingCartItem', 'Production.ProductDocument', 'dbo.DatabaseLog', 'Production.ProductInventory', 'Sales.SpecialOffer', 'dbo.ErrorLog', 'Production.ProductListPriceHistory']\n",
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922141221\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922141221')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/python-mssql-to-postgres-pyspark-20220922141221?project=617357862702\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922141221 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922141221 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922141221 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922141221 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922141221 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922141221\n",
      "['Person.Address', 'Sales.SpecialOfferProduct', 'Production.ProductModel', 'Person.AddressType', 'Person.StateProvince', 'Production.ProductModelIllustration', 'dbo.AWBuildVersion', 'Production.ProductModelProductDescriptionCulture', 'Production.BillOfMaterials', 'Sales.Store']\n",
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922141724\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922141724')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/python-mssql-to-postgres-pyspark-20220922141724?project=617357862702\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922141724 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922141724 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922141724 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922141724 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922141724 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922141724\n",
      "['Production.ProductPhoto', 'Production.ProductProductPhoto', 'Production.TransactionHistory', 'Production.ProductReview', 'Person.BusinessEntity', 'Production.TransactionHistoryArchive', 'Production.ProductSubcategory', 'Person.BusinessEntityAddress', 'Purchasing.ProductVendor', 'Person.BusinessEntityContact']\n",
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922142228\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922142228')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/python-mssql-to-postgres-pyspark-20220922142228?project=617357862702\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922142228 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922142228 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922142228 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922142228 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922142228 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922142228\n",
      "['Production.UnitMeasure', 'Purchasing.Vendor', 'Person.ContactType', 'Sales.CountryRegionCurrency', 'Person.CountryRegion', 'Production.WorkOrder', 'Purchasing.PurchaseOrderDetail', 'Sales.CreditCard', 'Production.Culture', 'Production.WorkOrderRouting']\n",
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922142720\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922142720')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/python-mssql-to-postgres-pyspark-20220922142720?project=617357862702\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922142720 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922142720 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922142720 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922142720 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922142720 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922142720\n",
      "['Sales.Currency', 'Purchasing.PurchaseOrderHeader', 'Sales.CurrencyRate', 'Sales.Customer', 'HumanResources.Department', 'Production.Document', 'Sales.SalesOrderDetail', 'Person.EmailAddress', 'HumanResources.Employee', 'Sales.SalesOrderHeader']\n",
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922143212\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922143212')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/python-mssql-to-postgres-pyspark-20220922143212?project=617357862702\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922143212 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922143212 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922143212 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922143212 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922143212 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922143212\n",
      "['HumanResources.EmployeeDepartmentHistory']\n",
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922143637\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922143637')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/python-mssql-to-postgres-pyspark-20220922143637?project=617357862702\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922143637 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922143637 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922143637 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922143637 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922143637 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/617357862702/locations/us-central1/pipelineJobs/python-mssql-to-postgres-pyspark-20220922143637\n"
     ]
    }
   ],
   "source": [
    "for execution_list in JOB_LIST:\n",
    "    print(execution_list)\n",
    "    migrate_mssql_to_postgres(execution_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb06f8bc-ef97-4665-8a5d-71e195c0d85d",
   "metadata": {},
   "source": [
    "## Step 11: Get status for tables migrated from MSSQL to POSTGRES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "136f4298-d5fd-4d3b-9f9a-12ef82d35b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bearer_token():\n",
    "    \n",
    "    try:\n",
    "        #Defining Scope\n",
    "        CREDENTIAL_SCOPES = [\"https://www.googleapis.com/auth/cloud-platform\"]\n",
    "\n",
    "        #Assigning credentials and project value\n",
    "        credentials, project_id = google.auth.default(scopes=CREDENTIAL_SCOPES)\n",
    "\n",
    "        #Refreshing credentials data\n",
    "        credentials.refresh(requests.Request())\n",
    "\n",
    "        #Get refreshed token\n",
    "        token = credentials.token\n",
    "        if token:\n",
    "            return (token,200)\n",
    "        else:\n",
    "            return \"Bearer token not generated\"\n",
    "    except Exception as error:\n",
    "        return (\"Bearer token not generated. Error : {}\".format(error),500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "2a5a8a6d-ca0b-4d1b-b325-f347b83f619d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bearer token generated\n"
     ]
    }
   ],
   "source": [
    "from google.auth.transport import requests\n",
    "import google\n",
    "\n",
    "token = get_bearer_token()\n",
    "if token[1] == 200:\n",
    "    print(\"Bearer token generated\")\n",
    "else:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "8dcbdd49-1125-446f-bfb4-52981fec44ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "mssql_to_postgres_status = []\n",
    "job_status_url = \"https://dataproc.googleapis.com/v1/projects/{}/locations/{}/batches/{}\"\n",
    "for job in mssql_to_postgres_jobs:\n",
    "    auth = \"Bearer \" + token[0]\n",
    "    url = job_status_url.format(PROJECT.value,REGION.value,job)\n",
    "    headers = {\n",
    "      'Content-Type': 'application/json; charset=UTF-8',\n",
    "      'Authorization': auth \n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    mssql_to_postgres_status.append(response.json()['state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "dde0a504-0f21-466d-b63a-b5e760344e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table</th>\n",
       "      <th>mssql_to_postgres_job</th>\n",
       "      <th>mssql_to_postgres_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HumanResources.EmployeePayHistory</td>\n",
       "      <td>mssqltopostgres-1663854464</td>\n",
       "      <td>SUCCEEDED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sales.SalesOrderHeaderSalesReason</td>\n",
       "      <td>mssqltopostgres-1663854467</td>\n",
       "      <td>SUCCEEDED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sales.SalesPerson</td>\n",
       "      <td>mssqltopostgres-1663854470</td>\n",
       "      <td>SUCCEEDED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Production.Illustration</td>\n",
       "      <td>mssqltopostgres-1663854473</td>\n",
       "      <td>SUCCEEDED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HumanResources.JobCandidate</td>\n",
       "      <td>mssqltopostgres-1663854476</td>\n",
       "      <td>SUCCEEDED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Sales.SalesOrderDetail</td>\n",
       "      <td>mssqltopostgres-1663857120</td>\n",
       "      <td>SUCCEEDED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Person.EmailAddress</td>\n",
       "      <td>mssqltopostgres-1663857123</td>\n",
       "      <td>SUCCEEDED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>HumanResources.Employee</td>\n",
       "      <td>mssqltopostgres-1663857126</td>\n",
       "      <td>SUCCEEDED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Sales.SalesOrderHeader</td>\n",
       "      <td>mssqltopostgres-1663857129</td>\n",
       "      <td>SUCCEEDED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>HumanResources.EmployeeDepartmentHistory</td>\n",
       "      <td>mssqltopostgres-1663857394</td>\n",
       "      <td>SUCCEEDED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       table       mssql_to_postgres_job  \\\n",
       "0          HumanResources.EmployeePayHistory  mssqltopostgres-1663854464   \n",
       "1          Sales.SalesOrderHeaderSalesReason  mssqltopostgres-1663854467   \n",
       "2                          Sales.SalesPerson  mssqltopostgres-1663854470   \n",
       "3                    Production.Illustration  mssqltopostgres-1663854473   \n",
       "4                HumanResources.JobCandidate  mssqltopostgres-1663854476   \n",
       "..                                       ...                         ...   \n",
       "86                    Sales.SalesOrderDetail  mssqltopostgres-1663857120   \n",
       "87                       Person.EmailAddress  mssqltopostgres-1663857123   \n",
       "88                   HumanResources.Employee  mssqltopostgres-1663857126   \n",
       "89                    Sales.SalesOrderHeader  mssqltopostgres-1663857129   \n",
       "90  HumanResources.EmployeeDepartmentHistory  mssqltopostgres-1663857394   \n",
       "\n",
       "   mssql_to_postgres_status  \n",
       "0                 SUCCEEDED  \n",
       "1                 SUCCEEDED  \n",
       "2                 SUCCEEDED  \n",
       "3                 SUCCEEDED  \n",
       "4                 SUCCEEDED  \n",
       "..                      ...  \n",
       "86                SUCCEEDED  \n",
       "87                SUCCEEDED  \n",
       "88                SUCCEEDED  \n",
       "89                SUCCEEDED  \n",
       "90                SUCCEEDED  \n",
       "\n",
       "[91 rows x 3 columns]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statusDF = pd.DataFrame({\"table\" : SQLTABLE_LIST,\"mssql_to_postgres_job\" : mssql_to_postgres_jobs, \"mssql_to_postgres_status\" : mssql_to_postgres_status})\n",
    "statusDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1386d002-3dc6-4b88-9288-45958cfc7c7a",
   "metadata": {},
   "source": [
    "## Step 12: Validate row counts of migrated tables from MSSQL to POSTGRES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "c80e8290-0c41-4fbf-ad93-6ec04de5d0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "mssql_row_count = []\n",
    "postgres_row_count = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "ae6e1f5a-8e58-4998-b8c7-50d26ea1433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mssql table counts\n",
    "DB = sqlalchemy.create_engine(\n",
    "            sqlalchemy.engine.url.URL.create(\n",
    "                drivername=PYMSSQL_DRIVER.value,\n",
    "                username=MSSQL_USERNAME.value,\n",
    "                password=MSSQL_PASSWORD.value,\n",
    "                database=MSSQL_DATABASE.value,\n",
    "                host=MSSQL_HOST.value,\n",
    "                port=MSSQL_PORT.value\n",
    "              )\n",
    "            )\n",
    "with DB.connect() as conn:\n",
    "    for table in SQLTABLE_LIST:\n",
    "        results = DB.execute(\"select count(*) from {}\".format(table)).fetchall()\n",
    "        for row in results:\n",
    "            mssql_row_count.append(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "d2f7c149-df59-4df0-87ec-7a2058503bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "postgresDB = psycopg2.connect(\n",
    "                user=POSTGRES_USERNAME.value,\n",
    "                password=POSTGRES_PASSWORD.value,\n",
    "                dbname=POSTGRES_DATABASE.value,\n",
    "                host=POSTGRES_HOST.value,\n",
    "                port=POSTGRES_PORT.value\n",
    "            )\n",
    "\n",
    "conn=postgresDB.cursor()\n",
    "for table in SQLTABLE_LIST:\n",
    "    conn.execute('''select count(*) from {}'''.format(table))\n",
    "    results = conn.fetchall()\n",
    "    for row in results:\n",
    "            postgres_row_count.append(row[0])\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "b48ac8aa-1843-4144-b6bc-6ab992b61ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table</th>\n",
       "      <th>mssql_to_postgres_job</th>\n",
       "      <th>mssql_to_postgres_status</th>\n",
       "      <th>mssql_row_count</th>\n",
       "      <th>postgres_row_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HumanResources.EmployeePayHistory</td>\n",
       "      <td>mssqltopostgres-1663854464</td>\n",
       "      <td>SUCCEEDED</td>\n",
       "      <td>316</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sales.SalesOrderHeaderSalesReason</td>\n",
       "      <td>mssqltopostgres-1663854467</td>\n",
       "      <td>SUCCEEDED</td>\n",
       "      <td>27647</td>\n",
       "      <td>27647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sales.SalesPerson</td>\n",
       "      <td>mssqltopostgres-1663854470</td>\n",
       "      <td>SUCCEEDED</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Production.Illustration</td>\n",
       "      <td>mssqltopostgres-1663854473</td>\n",
       "      <td>SUCCEEDED</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HumanResources.JobCandidate</td>\n",
       "      <td>mssqltopostgres-1663854476</td>\n",
       "      <td>SUCCEEDED</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Sales.SalesOrderDetail</td>\n",
       "      <td>mssqltopostgres-1663857120</td>\n",
       "      <td>SUCCEEDED</td>\n",
       "      <td>121317</td>\n",
       "      <td>121317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Person.EmailAddress</td>\n",
       "      <td>mssqltopostgres-1663857123</td>\n",
       "      <td>SUCCEEDED</td>\n",
       "      <td>19972</td>\n",
       "      <td>19972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>HumanResources.Employee</td>\n",
       "      <td>mssqltopostgres-1663857126</td>\n",
       "      <td>SUCCEEDED</td>\n",
       "      <td>290</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Sales.SalesOrderHeader</td>\n",
       "      <td>mssqltopostgres-1663857129</td>\n",
       "      <td>SUCCEEDED</td>\n",
       "      <td>31465</td>\n",
       "      <td>31465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>HumanResources.EmployeeDepartmentHistory</td>\n",
       "      <td>mssqltopostgres-1663857394</td>\n",
       "      <td>SUCCEEDED</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       table       mssql_to_postgres_job  \\\n",
       "0          HumanResources.EmployeePayHistory  mssqltopostgres-1663854464   \n",
       "1          Sales.SalesOrderHeaderSalesReason  mssqltopostgres-1663854467   \n",
       "2                          Sales.SalesPerson  mssqltopostgres-1663854470   \n",
       "3                    Production.Illustration  mssqltopostgres-1663854473   \n",
       "4                HumanResources.JobCandidate  mssqltopostgres-1663854476   \n",
       "..                                       ...                         ...   \n",
       "86                    Sales.SalesOrderDetail  mssqltopostgres-1663857120   \n",
       "87                       Person.EmailAddress  mssqltopostgres-1663857123   \n",
       "88                   HumanResources.Employee  mssqltopostgres-1663857126   \n",
       "89                    Sales.SalesOrderHeader  mssqltopostgres-1663857129   \n",
       "90  HumanResources.EmployeeDepartmentHistory  mssqltopostgres-1663857394   \n",
       "\n",
       "   mssql_to_postgres_status  mssql_row_count  postgres_row_count  \n",
       "0                 SUCCEEDED              316                 316  \n",
       "1                 SUCCEEDED            27647               27647  \n",
       "2                 SUCCEEDED               17                  17  \n",
       "3                 SUCCEEDED                5                   5  \n",
       "4                 SUCCEEDED               13                  13  \n",
       "..                      ...              ...                 ...  \n",
       "86                SUCCEEDED           121317              121317  \n",
       "87                SUCCEEDED            19972               19972  \n",
       "88                SUCCEEDED              290                 290  \n",
       "89                SUCCEEDED            31465               31465  \n",
       "90                SUCCEEDED              296                 296  \n",
       "\n",
       "[91 rows x 5 columns]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statusDF['mssql_row_count'] = mssql_row_count \n",
    "statusDF['postgres_row_count'] = postgres_row_count \n",
    "statusDF"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m95",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m95"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
