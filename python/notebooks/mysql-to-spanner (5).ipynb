{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1db5371a-8f16-47b7-bcc7-5af386e9b6d8",
   "metadata": {},
   "source": [
    "# <center>MySQL to Spanner Migration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d89b301-5249-462a-97d8-986488b303fd",
   "metadata": {},
   "source": [
    "## Step 1: Install Libraries\n",
    "#### Run Step 1 one time for each new notebook instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "fef65ec2-ad6b-407f-a993-7cdf871bba11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymysql in /opt/conda/lib/python3.7/site-packages (1.0.2)\n",
      "Requirement already satisfied: SQLAlchemy in /opt/conda/lib/python3.7/site-packages (1.4.39)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from SQLAlchemy) (4.11.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.7/site-packages (from SQLAlchemy) (1.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->SQLAlchemy) (3.8.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->SQLAlchemy) (4.3.0)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip3 install pymysql SQLAlchemy\n",
    "pip3 install --upgrade google-cloud-pipeline-components kfp --user -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "0e90943f-b965-4f7f-b631-ce62227d5e83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2022-09-01 00:40:24--  https://mirrors.estointernet.in/apache/maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gz\n",
      "Resolving mirrors.estointernet.in (mirrors.estointernet.in)... 43.255.166.254, 2403:8940:3:1::f\n",
      "Connecting to mirrors.estointernet.in (mirrors.estointernet.in)|43.255.166.254|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9506321 (9.1M) [application/octet-stream]\n",
      "Saving to: ‘apache-maven-3.6.3-bin.tar.gz.2’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  0%  108K 86s\n",
      "    50K .......... .......... .......... .......... ..........  1%  238K 62s\n",
      "   100K .......... .......... .......... .......... ..........  1%  440K 48s\n",
      "   150K .......... .......... .......... .......... ..........  2%  514K 40s\n",
      "   200K .......... .......... .......... .......... ..........  2%  550K 35s\n",
      "   250K .......... .......... .......... .......... ..........  3%  773K 31s\n",
      "   300K .......... .......... .......... .......... ..........  3% 1003K 28s\n",
      "   350K .......... .......... .......... .......... ..........  4%  792K 26s\n",
      "   400K .......... .......... .......... .......... ..........  4% 1.33M 23s\n",
      "   450K .......... .......... .......... .......... ..........  5% 1.28M 22s\n",
      "   500K .......... .......... .......... .......... ..........  5% 1.48M 20s\n",
      "   550K .......... .......... .......... .......... ..........  6% 1.59M 19s\n",
      "   600K .......... .......... .......... .......... ..........  7% 1.65M 18s\n",
      "   650K .......... .......... .......... .......... ..........  7% 2.02M 17s\n",
      "   700K .......... .......... .......... .......... ..........  8% 1.96M 16s\n",
      "   750K .......... .......... .......... .......... ..........  8% 1.57M 15s\n",
      "   800K .......... .......... .......... .......... ..........  9% 2.26M 14s\n",
      "   850K .......... .......... .......... .......... ..........  9% 2.58M 13s\n",
      "   900K .......... .......... .......... .......... .......... 10% 2.62M 13s\n",
      "   950K .......... .......... .......... .......... .......... 10% 2.78M 12s\n",
      "  1000K .......... .......... .......... .......... .......... 11% 2.93M 12s\n",
      "  1050K .......... .......... .......... .......... .......... 11% 3.14M 11s\n",
      "  1100K .......... .......... .......... .......... .......... 12% 3.14M 11s\n",
      "  1150K .......... .......... .......... .......... .......... 12% 2.57M 10s\n",
      "  1200K .......... .......... .......... .......... .......... 13% 3.74M 10s\n",
      "  1250K .......... .......... .......... .......... .......... 14% 3.35M 10s\n",
      "  1300K .......... .......... .......... .......... .......... 14% 3.96M 9s\n",
      "  1350K .......... .......... .......... .......... .......... 15% 3.82M 9s\n",
      "  1400K .......... .......... .......... .......... .......... 15% 4.08M 9s\n",
      "  1450K .......... .......... .......... .......... .......... 16% 4.46M 8s\n",
      "  1500K .......... .......... .......... .......... .......... 16% 4.02M 8s\n",
      "  1550K .......... .......... .......... .......... .......... 17% 3.46M 8s\n",
      "  1600K .......... .......... .......... .......... .......... 17% 4.28M 8s\n",
      "  1650K .......... .......... .......... .......... .......... 18% 4.77M 7s\n",
      "  1700K .......... .......... .......... .......... .......... 18% 4.85M 7s\n",
      "  1750K .......... .......... .......... .......... .......... 19% 5.39M 7s\n",
      "  1800K .......... .......... .......... .......... .......... 19% 4.71M 7s\n",
      "  1850K .......... .......... .......... .......... .......... 20% 5.60M 7s\n",
      "  1900K .......... .......... .......... .......... .......... 21% 5.21M 6s\n",
      "  1950K .......... .......... .......... .......... .......... 21% 4.07M 6s\n",
      "  2000K .......... .......... .......... .......... .......... 22% 6.06M 6s\n",
      "  2050K .......... .......... .......... .......... .......... 22% 5.72M 6s\n",
      "  2100K .......... .......... .......... .......... .......... 23% 6.23M 6s\n",
      "  2150K .......... .......... .......... .......... .......... 23% 6.26M 6s\n",
      "  2200K .......... .......... .......... .......... .......... 24% 5.77M 6s\n",
      "  2250K .......... .......... .......... .......... .......... 24% 7.06M 5s\n",
      "  2300K .......... .......... .......... .......... .......... 25% 6.42M 5s\n",
      "  2350K .......... .......... .......... .......... .......... 25% 5.14M 5s\n",
      "  2400K .......... .......... .......... .......... .......... 26% 7.93M 5s\n",
      "  2450K .......... .......... .......... .......... .......... 26% 6.87M 5s\n",
      "  2500K .......... .......... .......... .......... .......... 27% 7.18M 5s\n",
      "  2550K .......... .......... .......... .......... .......... 28% 7.32M 5s\n",
      "  2600K .......... .......... .......... .......... .......... 28% 7.29M 5s\n",
      "  2650K .......... .......... .......... .......... .......... 29% 6.96M 4s\n",
      "  2700K .......... .......... .......... .......... .......... 29% 9.78M 4s\n",
      "  2750K .......... .......... .......... .......... .......... 30% 5.86M 4s\n",
      "  2800K .......... .......... .......... .......... .......... 30% 8.08M 4s\n",
      "  2850K .......... .......... .......... .......... .......... 31% 8.91M 4s\n",
      "  2900K .......... .......... .......... .......... .......... 31% 8.26M 4s\n",
      "  2950K .......... .......... .......... .......... .......... 32% 8.61M 4s\n",
      "  3000K .......... .......... .......... .......... .......... 32% 7.33M 4s\n",
      "  3050K .......... .......... .......... .......... .......... 33% 11.1M 4s\n",
      "  3100K .......... .......... .......... .......... .......... 33% 7.05M 4s\n",
      "  3150K .......... .......... .......... .......... .......... 34% 7.62M 4s\n",
      "  3200K .......... .......... .......... .......... .......... 35% 10.1M 4s\n",
      "  3250K .......... .......... .......... .......... .......... 35% 9.44M 3s\n",
      "  3300K .......... .......... .......... .......... .......... 36% 9.64M 3s\n",
      "  3350K .......... .......... .......... .......... .......... 36% 9.56M 3s\n",
      "  3400K .......... .......... .......... .......... .......... 37% 8.45M 3s\n",
      "  3450K .......... .......... .......... .......... .......... 37% 10.4M 3s\n",
      "  3500K .......... .......... .......... .......... .......... 38% 8.63M 3s\n",
      "  3550K .......... .......... .......... .......... .......... 38% 8.95M 3s\n",
      "  3600K .......... .......... .......... .......... .......... 39% 9.36M 3s\n",
      "  3650K .......... .......... .......... .......... .......... 39% 9.62M 3s\n",
      "  3700K .......... .......... .......... .......... .......... 40% 9.54M 3s\n",
      "  3750K .......... .......... .......... .......... .......... 40% 11.4M 3s\n",
      "  3800K .......... .......... .......... .......... .......... 41% 11.1M 3s\n",
      "  3850K .......... .......... .......... .......... .......... 42% 9.02M 3s\n",
      "  3900K .......... .......... .......... .......... .......... 42% 13.3M 3s\n",
      "  3950K .......... .......... .......... .......... .......... 43% 8.02M 3s\n",
      "  4000K .......... .......... .......... .......... .......... 43% 14.1M 3s\n",
      "  4050K .......... .......... .......... .......... .......... 44% 9.66M 3s\n",
      "  4100K .......... .......... .......... .......... .......... 44% 14.2M 2s\n",
      "  4150K .......... .......... .......... .......... .......... 45% 9.08M 2s\n",
      "  4200K .......... .......... .......... .......... .......... 45% 12.7M 2s\n",
      "  4250K .......... .......... .......... .......... .......... 46% 12.3M 2s\n",
      "  4300K .......... .......... .......... .......... .......... 46% 14.8M 2s\n",
      "  4350K .......... .......... .......... .......... .......... 47% 8.88M 2s\n",
      "  4400K .......... .......... .......... .......... .......... 47% 12.1M 2s\n",
      "  4450K .......... .......... .......... .......... .......... 48% 13.3M 2s\n",
      "  4500K .......... .......... .......... .......... .......... 49% 11.5M 2s\n",
      "  4550K .......... .......... .......... .......... .......... 49% 15.1M 2s\n",
      "  4600K .......... .......... .......... .......... .......... 50% 13.0M 2s\n",
      "  4650K .......... .......... .......... .......... .......... 50% 12.4M 2s\n",
      "  4700K .......... .......... .......... .......... .......... 51% 15.3M 2s\n",
      "  4750K .......... .......... .......... .......... .......... 51% 8.25M 2s\n",
      "  4800K .......... .......... .......... .......... .......... 52% 21.4M 2s\n",
      "  4850K .......... .......... .......... .......... .......... 52% 13.4M 2s\n",
      "  4900K .......... .......... .......... .......... .......... 53% 13.5M 2s\n",
      "  4950K .......... .......... .......... .......... .......... 53% 11.2M 2s\n",
      "  5000K .......... .......... .......... .......... .......... 54% 15.0M 2s\n",
      "  5050K .......... .......... .......... .......... .......... 54% 14.3M 2s\n",
      "  5100K .......... .......... .......... .......... .......... 55% 19.5M 2s\n",
      "  5150K .......... .......... .......... .......... .......... 56% 11.3M 2s\n",
      "  5200K .......... .......... .......... .......... .......... 56% 16.5M 2s\n",
      "  5250K .......... .......... .......... .......... .......... 57% 12.6M 2s\n",
      "  5300K .......... .......... .......... .......... .......... 57% 13.1M 2s\n",
      "  5350K .......... .......... .......... .......... .......... 58% 17.9M 1s\n",
      "  5400K .......... .......... .......... .......... .......... 58% 14.1M 1s\n",
      "  5450K .......... .......... .......... .......... .......... 59% 16.3M 1s\n",
      "  5500K .......... .......... .......... .......... .......... 59% 18.0M 1s\n",
      "  5550K .......... .......... .......... .......... .......... 60% 1.07M 1s\n",
      "  5600K .......... .......... .......... .......... .......... 60% 17.2M 1s\n",
      "  5650K .......... .......... .......... .......... .......... 61% 16.5M 1s\n",
      "  5700K .......... .......... .......... .......... .......... 61% 19.4M 1s\n",
      "  5750K .......... .......... .......... .......... .......... 62% 20.7M 1s\n",
      "  5800K .......... .......... .......... .......... .......... 63% 17.0M 1s\n",
      "  5850K .......... .......... .......... .......... .......... 63% 17.8M 1s\n",
      "  5900K .......... .......... .......... .......... .......... 64% 21.9M 1s\n",
      "  5950K .......... .......... .......... .......... .......... 64% 15.0M 1s\n",
      "  6000K .......... .......... .......... .......... .......... 65% 32.8M 1s\n",
      "  6050K .......... .......... .......... .......... .......... 65% 26.3M 1s\n",
      "  6100K .......... .......... .......... .......... .......... 66% 22.1M 1s\n",
      "  6150K .......... .......... .......... .......... .......... 66% 40.6M 1s\n",
      "  6200K .......... .......... .......... .......... .......... 67% 36.0M 1s\n",
      "  6250K .......... .......... .......... .......... .......... 67% 23.0M 1s\n",
      "  6300K .......... .......... .......... .......... .......... 68% 24.8M 1s\n",
      "  6350K .......... .......... .......... .......... .......... 68% 23.1M 1s\n",
      "  6400K .......... .......... .......... .......... .......... 69% 34.0M 1s\n",
      "  6450K .......... .......... .......... .......... .......... 70% 24.8M 1s\n",
      "  6500K .......... .......... .......... .......... .......... 70% 23.3M 1s\n",
      "  6550K .......... .......... .......... .......... .......... 71% 20.4M 1s\n",
      "  6600K .......... .......... .......... .......... .......... 71% 13.8M 1s\n",
      "  6650K .......... .......... .......... .......... .......... 72% 8.22M 1s\n",
      "  6700K .......... .......... .......... .......... .......... 72% 7.50M 1s\n",
      "  6750K .......... .......... .......... .......... .......... 73% 10.3M 1s\n",
      "  6800K .......... .......... .......... .......... .......... 73% 13.2M 1s\n",
      "  6850K .......... .......... .......... .......... .......... 74% 8.24M 1s\n",
      "  6900K .......... .......... .......... .......... .......... 74% 9.29M 1s\n",
      "  6950K .......... .......... .......... .......... .......... 75% 1022K 1s\n",
      "  7000K .......... .......... .......... .......... .......... 75% 30.7M 1s\n",
      "  7050K .......... .......... .......... .......... .......... 76% 22.6M 1s\n",
      "  7100K .......... .......... .......... .......... .......... 77% 40.3M 1s\n",
      "  7150K .......... .......... .......... .......... .......... 77% 37.9M 1s\n",
      "  7200K .......... .......... .......... .......... .......... 78% 53.3M 1s\n",
      "  7250K .......... .......... .......... .......... .......... 78%  117M 1s\n",
      "  7300K .......... .......... .......... .......... .......... 79% 43.4M 1s\n",
      "  7350K .......... .......... .......... .......... .......... 79% 44.2M 1s\n",
      "  7400K .......... .......... .......... .......... .......... 80% 42.9M 1s\n",
      "  7450K .......... .......... .......... .......... .......... 80% 71.6M 1s\n",
      "  7500K .......... .......... .......... .......... .......... 81% 58.8M 1s\n",
      "  7550K .......... .......... .......... .......... .......... 81% 43.4M 1s\n",
      "  7600K .......... .......... .......... .......... .......... 82% 45.1M 0s\n",
      "  7650K .......... .......... .......... .......... .......... 82% 43.0M 0s\n",
      "  7700K .......... .......... .......... .......... .......... 83% 31.7M 0s\n",
      "  7750K .......... .......... .......... .......... .......... 84% 12.4M 0s\n",
      "  7800K .......... .......... .......... .......... .......... 84% 20.6M 0s\n",
      "  7850K .......... .......... .......... .......... .......... 85% 13.1M 0s\n",
      "  7900K .......... .......... .......... .......... .......... 85% 7.44M 0s\n",
      "  7950K .......... .......... .......... .......... .......... 86% 14.9M 0s\n",
      "  8000K .......... .......... .......... .......... .......... 86% 17.1M 0s\n",
      "  8050K .......... .......... .......... .......... .......... 87% 15.7M 0s\n",
      "  8100K .......... .......... .......... .......... .......... 87% 13.9M 0s\n",
      "  8150K .......... .......... .......... .......... .......... 88% 13.1M 0s\n",
      "  8200K .......... .......... .......... .......... .......... 88% 12.9M 0s\n",
      "  8250K .......... .......... .......... .......... .......... 89% 15.4M 0s\n",
      "  8300K .......... .......... .......... .......... .......... 89% 19.0M 0s\n",
      "  8350K .......... .......... .......... .......... .......... 90% 11.8M 0s\n",
      "  8400K .......... .......... .......... .......... .......... 91%  695K 0s\n",
      "  8450K .......... .......... .......... .......... .......... 91% 31.5M 0s\n",
      "  8500K .......... .......... .......... .......... .......... 92% 26.8M 0s\n",
      "  8550K .......... .......... .......... .......... .......... 92% 34.3M 0s\n",
      "  8600K .......... .......... .......... .......... .......... 93% 28.1M 0s\n",
      "  8650K .......... .......... .......... .......... .......... 93% 47.1M 0s\n",
      "  8700K .......... .......... .......... .......... .......... 94% 24.8M 0s\n",
      "  8750K .......... .......... .......... .......... .......... 94% 21.0M 0s\n",
      "  8800K .......... .......... .......... .......... .......... 95% 56.7M 0s\n",
      "  8850K .......... .......... .......... .......... .......... 95% 30.4M 0s\n",
      "  8900K .......... .......... .......... .......... .......... 96% 38.4M 0s\n",
      "  8950K .......... .......... .......... .......... .......... 96% 27.5M 0s\n",
      "  9000K .......... .......... .......... .......... .......... 97% 43.8M 0s\n",
      "  9050K .......... .......... .......... .......... .......... 98% 24.6M 0s\n",
      "  9100K .......... .......... .......... .......... .......... 98% 46.2M 0s\n",
      "  9150K .......... .......... .......... .......... .......... 99% 29.5M 0s\n",
      "  9200K .......... .......... .......... .......... .......... 99% 28.5M 0s\n",
      "  9250K .......... .......... .......... ...                  100%  167M=2.4s\n",
      "\n",
      "2022-09-01 00:40:27 (3.74 MB/s) - ‘apache-maven-3.6.3-bin.tar.gz.2’ saved [9506321/9506321]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wget https://mirrors.estointernet.in/apache/maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gz\n",
    "tar -xf apache-maven-3.6.3-bin.tar.gz\n",
    "sudo rm -rf /usr/bin/apache-maven-3.6.3\n",
    "sudo mv apache-maven-3.6.3 /usr/bin/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d01e33-9099-4d2e-b57e-575c3a998d84",
   "metadata": {},
   "source": [
    "## Step 2: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2703b502-1b41-44f1-bf21-41069255bc32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "import pymysql\n",
    "import google.cloud.aiplatform as aiplatform\n",
    "from kfp import dsl\n",
    "from kfp.v2 import compiler\n",
    "from datetime import datetime\n",
    "import time\n",
    "import copy\n",
    "import json\n",
    "import pandas as pd\n",
    "from google_cloud_pipeline_components.experimental.dataproc import DataprocSparkBatchOp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c4a209-db59-42f6-bba7-30cd46b16bad",
   "metadata": {},
   "source": [
    "## Step 3: Assign Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d3fbd8-013f-45e6-b7e9-8f31a4580e91",
   "metadata": {},
   "source": [
    "### Step 3.1 Common Parameters\n",
    "\n",
    "###### PROJECT : GCP project-id\n",
    "###### REGION : GCP region\n",
    "###### GCS_STAGING_LOCATION : GCS staging locatio to be used for this notebook\n",
    "###### SUBNET : subnet\n",
    "###### JARS : list of jars. For this notebook mysql connector and avro jar is required in addition with the dataproc template jars\n",
    "###### MAX_PARALLELISM : Parameter for number of jobs to run in parallel default value is 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd8f6dd9-2e13-447c-b28d-10fa2321b759",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT = \"yadavaja-sandbox\"\n",
    "REGION = \"us-west1\"\n",
    "GCS_STAGING_LOCATION = \"gs://python-dataproc-templates-temp/mysql-to-spanner-staging\"\n",
    "SUBNET = \"projects/yadavaja-sandbox/regions/us-west1/subnetworks/test-subnet1\"\n",
    "JARS = [\"gs://datproc_template_nk/jars/mysql-connector-java-8.0.29.jar\",\"file:///usr/lib/spark/external/spark-avro.jar\"]\n",
    "MAX_PARALLELISM = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051df2af-bd8b-47c7-8cb2-05404ca0d859",
   "metadata": {},
   "source": [
    "### Step 3.2 MYSQL to GCS Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71dd2824-e9a0-4ceb-a3c9-32f79973432a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MYSQL_HOST = \"10.203.209.12\"\n",
    "MYSQL_PORT = \"3306\"\n",
    "MYSQL_USERNAME = \"root\"\n",
    "MYSQL_PASSWORD = \"naveen\"\n",
    "MYSQL_DATABASE = \"nk\"\n",
    "MYSQLTABLE_LIST = ['employees','employees_nop','employees_mup'] # leave list empty for migrating complete database\n",
    "MYSQL_OUTPUT_GCS_LOCATION = \"gs://python-dataproc-templates/mysql-gcs-output\"\n",
    "MYSQL_OUTPUT_GCS_MODE = \"overwrite\"\n",
    "MYSQL_OUTPUT_GCS_FORMAT = \"avro\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918048e3-4e98-4a91-8f5c-7c2cf1da559c",
   "metadata": {},
   "source": [
    "### Step 3.3 GCS to SPANNER Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9590468f-8782-4ccc-b2eb-62a9ea2599d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SPANNER_INSTANCE = \"dataproc-spark-test\"\n",
    "SPANNER_DATABASE = \"spark-ci-db\"\n",
    "SPANNER_TABLE_PRIMARY_KEYS = {\"employees_nop\" : \"id\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166b1536-d58e-423b-b3c2-cc0c171d275e",
   "metadata": {},
   "source": [
    "### Step 3.4 Notebook Configuration Parameters\n",
    "Below variables shoulld not be changed unless required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6f0f037-e888-4479-a143-f06a39bd5cc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PYMYSQL_DRIVER = \"mysql+pymysql\"\n",
    "JDBC_DRIVER = \"com.mysql.cj.jdbc.Driver\"\n",
    "JDBC_URL = \"jdbc:mysql://{}:{}/{}?user={}&password={}\".format(MYSQL_HOST,MYSQL_PORT,MYSQL_DATABASE,MYSQL_USERNAME,MYSQL_PASSWORD)\n",
    "MAIN_CLASS = \"com.google.cloud.dataproc.templates.main.DataProcTemplate\"\n",
    "WORKING_DIRECTORY = \"/home/jupyter/dataproc-templates/java/\"\n",
    "JAR_FILE = \"dataproc-templates-1.0-SNAPSHOT.jar\"\n",
    "GRPC_JAR_PATH = \"./grpc_lb/io/grpc/grpc-grpclb/1.40.1\"\n",
    "GRPC_JAR = \"grpc-grpclb-1.40.1.jar\"\n",
    "LOG4J_PROPERTIES_PATH = \"./src/test/resources\"\n",
    "LOG4J_PROPERTIES = \"log4j-spark-driver-template.properties\"\n",
    "PIPELINE_ROOT = GCS_STAGING_LOCATION + \"/pipeline_root/dataproc_pyspark\"\n",
    "\n",
    "JARS.append(GCS_STAGING_LOCATION + \"/\" + GRPC_JAR)\n",
    "JARS.append(GCS_STAGING_LOCATION + \"/\" + JAR_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115c062b-5a91-4372-b440-5c37a12fbf87",
   "metadata": {},
   "source": [
    "## Step 4: Generate MySQL Table List\n",
    "This step creates list of tables for migration. If MYSQLTABLE_LIST is kept empty all the tables in the MYSQL_DATABASE are listed for migration otherwise the provided list is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0e362ac-30cd-4857-9e2a-0e9eb926e627",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of tables for migration :\n",
      "['employees', 'employees_nop', 'employees_mup']\n"
     ]
    }
   ],
   "source": [
    "if len(MYSQLTABLE_LIST) == 0:\n",
    "    DB = sqlalchemy.create_engine(\n",
    "            sqlalchemy.engine.url.URL.create(\n",
    "                drivername=PYMYSQL_DRIVER,\n",
    "                username=MYSQL_USERNAME,\n",
    "                password=MYSQL_PASSWORD,\n",
    "                database=MYSQL_DATABASE,\n",
    "                host=MYSQL_HOST,\n",
    "                port=MYSQL_PORT\n",
    "              )\n",
    "            )\n",
    "    with DB.connect() as conn:\n",
    "        print(\"connected to database\")\n",
    "        results = DB.execute('show tables;').fetchall()\n",
    "        print(\"Total Tables = \", len(results))\n",
    "        for row in results:\n",
    "            TABLE_LIST.append(row[0])\n",
    "\n",
    "print(\"list of tables for migration :\")\n",
    "print(MYSQLTABLE_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9a62e8-7499-41c6-b32b-73b539b0c7c4",
   "metadata": {},
   "source": [
    "## Step 5: Get Primary Keys for tables not present in SPANNER_TABLE_PRIMARY_KEYS\n",
    "For tables which do not have primary key provided in dictonary SPANNER_TABLE_PRIMARY_KEYS this step fetches primary key from MYSQL_DATABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6eda8fac-582c-4d4a-b871-311bb2863335",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DB = sqlalchemy.create_engine(\n",
    "            sqlalchemy.engine.url.URL.create(\n",
    "                drivername=PYMYSQL_DRIVER,\n",
    "                username=MYSQL_USERNAME,\n",
    "                password=MYSQL_PASSWORD,\n",
    "                database=MYSQL_DATABASE,\n",
    "                host=MYSQL_HOST,\n",
    "                port=MYSQL_PORT\n",
    "              )\n",
    "            )\n",
    "with DB.connect() as conn:\n",
    "    for table in MYSQLTABLE_LIST:\n",
    "        primary_keys = []\n",
    "        if table not in SPANNER_TABLE_PRIMARY_KEYS:\n",
    "            results = DB.execute(\"SHOW KEYS FROM {} WHERE Key_name = 'PRIMARY'\".format(table)).fetchall()\n",
    "            for row in results:\n",
    "                primary_keys.append(row[4])\n",
    "            if primary_keys:\n",
    "                SPANNER_TABLE_PRIMARY_KEYS[table] = \",\".join(primary_keys)\n",
    "            else:\n",
    "                SPANNER_TABLE_PRIMARY_KEYS[table] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c2a210f-48da-474f-bf46-89e755d01c67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are identified primary keys for migrating mysql table to spanner:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table</th>\n",
       "      <th>primary_keys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>employees</td>\n",
       "      <td>id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>employees_nop</td>\n",
       "      <td>id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>employees_mup</td>\n",
       "      <td>id,fname</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           table primary_keys\n",
       "0      employees           id\n",
       "1  employees_nop           id\n",
       "2  employees_mup     id,fname"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkDF = pd.DataFrame({\"table\" : MYSQLTABLE_LIST, \"primary_keys\": list(SPANNER_TABLE_PRIMARY_KEYS.values())})\n",
    "print(\"Below are identified primary keys for migrating mysql table to spanner:\")\n",
    "pkDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa5f841-a687-4723-a8e6-6e7e752ba36e",
   "metadata": {},
   "source": [
    "## Step 6: Create JAR files and Upload to GCS\n",
    "#### Run Step 6 one time for each new notebook instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22220ae3-9fb4-471c-b5aa-f606deeca15e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/dataproc-templates/java\n"
     ]
    }
   ],
   "source": [
    "%cd $WORKING_DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b40f634-1983-4267-a4c1-b072bf6d81ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "export MAVEN_HOME=\"/usr/bin/apache-maven-3.6.3\"\n",
    "export PATH=\"$MAVEN_HOME/bin:$PATH\"\n",
    "export PATH\n",
    "mvn clean spotless:apply install -DskipTests \n",
    "mvn dependency:get -Dartifact=io.grpc:grpc-grpclb:1.40.1 -Dmaven.repo.local=./grpc_lb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "939cdcd5-0f3e-4f51-aa78-93d1976cb0f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://target/dataproc-templates-1.0-SNAPSHOT.jar [Content-Type=application/java-archive]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "\\ [1 files][158.5 MiB/158.5 MiB]                                                \n",
      "Operation completed over 1 objects/158.5 MiB.                                    \n",
      "Copying file://./grpc_lb/io/grpc/grpc-grpclb/1.40.1/grpc-grpclb-1.40.1.jar [Content-Type=application/java-archive]...\n",
      "/ [1 files][174.5 KiB/174.5 KiB]                                                \n",
      "Operation completed over 1 objects/174.5 KiB.                                    \n",
      "Copying file://./src/test/resources/log4j-spark-driver-template.properties [Content-Type=application/octet-stream]...\n",
      "/ [1 files][  861.0 B/  861.0 B]                                                \n",
      "Operation completed over 1 objects/861.0 B.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp target/$JAR_FILE $GCS_STAGING_LOCATION/$JAR_FILE\n",
    "!gsutil cp $GRPC_JAR_PATH/$GRPC_JAR $GCS_STAGING_LOCATION/$GRPC_JAR\n",
    "!gsutil cp $LOG4J_PROPERTIES_PATH/$LOG4J_PROPERTIES $GCS_STAGING_LOCATION/$LOG4J_PROPERTIES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9bb170-09c4-40d1-baaf-9e907f215889",
   "metadata": {},
   "source": [
    "## Step 7: Calculate Parallel Jobs for MySQL to GCS\n",
    "This step uses MAX_PARALLELISM parameter to calculate number of parallel jobs to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c501db0-c1fb-4a05-88b8-a7e546e2b1d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of tables for execution : \n",
      "[['employees', 'employees_nop'], ['employees_mup']]\n"
     ]
    }
   ],
   "source": [
    "# calculate parallel jobs:\n",
    "COMPLETE_LIST = copy.deepcopy(MYSQLTABLE_LIST)\n",
    "PARALLEL_JOBS = len(MYSQLTABLE_LIST)//MAX_PARALLELISM\n",
    "JOB_LIST = []\n",
    "while len(COMPLETE_LIST) > 0:\n",
    "    SUB_LIST = []\n",
    "    for i in range(MAX_PARALLELISM):\n",
    "        if len(COMPLETE_LIST)>0 :\n",
    "            SUB_LIST.append(COMPLETE_LIST[0].lower())\n",
    "            COMPLETE_LIST.pop(0)\n",
    "        else:\n",
    "            break\n",
    "    JOB_LIST.append(SUB_LIST)\n",
    "print(\"list of tables for execution : \")\n",
    "print(JOB_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f6f83b-891a-4515-a1d6-f3406a25dc2a",
   "metadata": {},
   "source": [
    "## Step 8: Execute Pipeline to Migrate tables from MySQL to GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f98914b-bd74-4d0e-9562-7019d504a25e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mysql_to_gcs_jobs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "863fa2d8-4ef7-4722-87c8-eec6c06f892b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def migrate_mysql_to_gcs(EXECUTION_LIST):\n",
    "    EXECUTION_LIST = EXECUTION_LIST\n",
    "    aiplatform.init(project=PROJECT,staging_bucket=GCS_STAGING_LOCATION)\n",
    "    \n",
    "    @dsl.pipeline(\n",
    "        name=\"java-mysql-to-gcs-pyspark\",\n",
    "        description=\"Pipeline to get data from mysql to gcs\",\n",
    "    )\n",
    "    def pipeline(\n",
    "        PROJECT_ID: str = PROJECT,\n",
    "        LOCATION: str = REGION,\n",
    "        MAIN_CLASS: str = MAIN_CLASS,\n",
    "        JAR_FILE_URIS: list = JARS,\n",
    "        SUBNETWORK_URI: str = SUBNET,\n",
    "        FILE_URIS: list = [GCS_STAGING_LOCATION + \"/\" + LOG4J_PROPERTIES]\n",
    "    ):\n",
    "        for table in EXECUTION_LIST:\n",
    "            BATCH_ID = \"mysql2gcs-{}\".format(datetime.now().strftime(\"%s\"))\n",
    "            mysql_to_gcs_jobs.append(BATCH_ID)\n",
    "            TEMPLATE_SPARK_ARGS = [\n",
    "            \"--template=JDBCTOGCS\",\n",
    "            \"--templateProperty\", \"project.id={}\".format(PROJECT),\n",
    "            \"-templateProperty\", \"jdbctogcs.jdbc.url={}\".format(JDBC_URL),\n",
    "            \"--templateProperty\", \"jdbctogcs.jdbc.driver.class.name={}\".format(JDBC_DRIVER),\n",
    "            \"--templateProperty\",\"jdbctogcs.output.location={}/{}\".format(MYSQL_OUTPUT_GCS_LOCATION,table),\n",
    "            \"--templateProperty\", \"jdbctogcs.output.format={}\".format(MYSQL_OUTPUT_GCS_FORMAT),\n",
    "            \"--templateProperty\", \"jdbctogcs.write.mode={}\".format(MYSQL_OUTPUT_GCS_MODE),\n",
    "            \"--templateProperty\", \"jdbctogcs.sql=select * from {}\".format(table),\n",
    "            ]\n",
    "\n",
    "            _ = DataprocSparkBatchOp(\n",
    "                project=PROJECT_ID,\n",
    "                location=LOCATION,\n",
    "                batch_id=BATCH_ID,\n",
    "                main_class=MAIN_CLASS,\n",
    "                jar_file_uris=JAR_FILE_URIS,\n",
    "                file_uris=FILE_URIS,\n",
    "                subnetwork_uri=SUBNETWORK_URI,\n",
    "                args=TEMPLATE_SPARK_ARGS\n",
    "            )\n",
    "            time.sleep(3)\n",
    "\n",
    "    compiler.Compiler().compile(pipeline_func=pipeline, package_path=\"pipeline.json\")\n",
    "\n",
    "    pipeline = aiplatform.PipelineJob(\n",
    "            display_name=\"pipeline\",\n",
    "        template_path=\"pipeline.json\",\n",
    "        pipeline_root=PIPELINE_ROOT,\n",
    "        enable_caching=False,\n",
    "        )\n",
    "    pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44205b54-1ac7-42f3-85ad-5b20f531056b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['employees', 'employees_nop']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.7/site-packages/kfp/v2/compiler/compiler.py:1295: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
      "  category=FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/617357862702/locations/us-central1/pipelineJobs/java-mysql-to-gcs-pyspark-20220901005246\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/617357862702/locations/us-central1/pipelineJobs/java-mysql-to-gcs-pyspark-20220901005246')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/java-mysql-to-gcs-pyspark-20220901005246?project=617357862702\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/java-mysql-to-gcs-pyspark-20220901005246 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/java-mysql-to-gcs-pyspark-20220901005246 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/java-mysql-to-gcs-pyspark-20220901005246 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/java-mysql-to-gcs-pyspark-20220901005246 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/java-mysql-to-gcs-pyspark-20220901005246 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/java-mysql-to-gcs-pyspark-20220901005246 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/617357862702/locations/us-central1/pipelineJobs/java-mysql-to-gcs-pyspark-20220901005246\n",
      "['employees_mup']\n",
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/617357862702/locations/us-central1/pipelineJobs/java-mysql-to-gcs-pyspark-20220901005834\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/617357862702/locations/us-central1/pipelineJobs/java-mysql-to-gcs-pyspark-20220901005834')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/java-mysql-to-gcs-pyspark-20220901005834?project=617357862702\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/java-mysql-to-gcs-pyspark-20220901005834 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/java-mysql-to-gcs-pyspark-20220901005834 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/java-mysql-to-gcs-pyspark-20220901005834 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/java-mysql-to-gcs-pyspark-20220901005834 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/java-mysql-to-gcs-pyspark-20220901005834 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/617357862702/locations/us-central1/pipelineJobs/java-mysql-to-gcs-pyspark-20220901005834\n"
     ]
    }
   ],
   "source": [
    "for execution_list in JOB_LIST:\n",
    "    print(execution_list)\n",
    "    migrate_mysql_to_gcs(execution_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce7f828-dacc-404b-8927-dc3813e7216a",
   "metadata": {},
   "source": [
    "## Step 9: Get status for tables migrated from MySql to GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b611510f-271c-447a-899d-42fbb983268d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_bearer_token():\n",
    "    \n",
    "    try:\n",
    "        #Defining Scope\n",
    "        CREDENTIAL_SCOPES = [\"https://www.googleapis.com/auth/cloud-platform\"]\n",
    "\n",
    "        #Assining credentials and project value\n",
    "        credentials, project_id = google.auth.default(scopes=CREDENTIAL_SCOPES)\n",
    "\n",
    "        #Refreshing credentials data\n",
    "        credentials.refresh(requests.Request())\n",
    "\n",
    "        #Get refreshed token\n",
    "        token = credentials.token\n",
    "        if token:\n",
    "            return (token,200)\n",
    "        else:\n",
    "            return \"Bearer token not generated\"\n",
    "    except Exception as error:\n",
    "        return (\"Bearer token not generated. Error : {}\".format(error),500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1fcbc63-19db-42a8-a2ed-d9855da00c04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bearer token generated\n"
     ]
    }
   ],
   "source": [
    "from google.auth.transport import requests\n",
    "import google\n",
    "token = get_bearer_token()\n",
    "if token[1] == 200:\n",
    "    print(\"Bearer token generated\")\n",
    "else:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5be3cf87-6d28-4b23-8466-87d3399f7a29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "mysql_to_gcs_status = []\n",
    "job_status_url = \"https://dataproc.googleapis.com/v1/projects/{}/locations/{}/batches/{}\"\n",
    "for job in mysql_to_gcs_jobs:\n",
    "    auth = \"Bearer \" + token[0]\n",
    "    url = job_status_url.format(PROJECT,REGION,job)\n",
    "    headers = {\n",
    "      'Content-Type': 'application/json; charset=UTF-8',\n",
    "      'Authorization': auth \n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    mysql_to_gcs_status.append(response.json()['state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1097575d-07c2-4659-a75f-d7e898e3f077",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table</th>\n",
       "      <th>mysql_to_gcs_job</th>\n",
       "      <th>mysql_to_gcs_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>employees</td>\n",
       "      <td>mysql2gcs-1661993560</td>\n",
       "      <td>SUCCEEDED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>employees_nop</td>\n",
       "      <td>mysql2gcs-1661993563</td>\n",
       "      <td>SUCCEEDED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>employees_mup</td>\n",
       "      <td>mysql2gcs-1661993911</td>\n",
       "      <td>SUCCEEDED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           table      mysql_to_gcs_job mysql_to_gcs_status\n",
       "0      employees  mysql2gcs-1661993560           SUCCEEDED\n",
       "1  employees_nop  mysql2gcs-1661993563           SUCCEEDED\n",
       "2  employees_mup  mysql2gcs-1661993911           SUCCEEDED"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statusDF = pd.DataFrame({\"table\" : MYSQLTABLE_LIST,\"mysql_to_gcs_job\" : mysql_to_gcs_jobs, \"mysql_to_gcs_status\" : mysql_to_gcs_status})\n",
    "statusDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b70a6d4-3372-4f5c-bdf6-e0c856ec4318",
   "metadata": {},
   "source": [
    "## Step 10: Execute Pipeline to Migrate tables from GCS to SPANNER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d42a236-4970-4859-9094-39b4fd3a41bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gcs_to_spanner_jobs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d7fa0ac-c99d-4d35-b7d8-5fd5ca23d12b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def migrate_gcs_to_spanner(EXECUTION_LIST):\n",
    "    EXECUTION_LIST = EXECUTION_LIST\n",
    "    aiplatform.init(project=PROJECT, staging_bucket=GCS_STAGING_LOCATION)\n",
    "\n",
    "\n",
    "    @dsl.pipeline(\n",
    "        name=\"java-gcs-to-spanner-pyspark\",\n",
    "        description=\"Pipeline to get data from gcs to spanner\",\n",
    "    )\n",
    "    def pipeline(\n",
    "        PROJECT_ID: str = PROJECT,\n",
    "        LOCATION: str = REGION,\n",
    "        MAIN_CLASS: str = MAIN_CLASS,\n",
    "        JAR_FILE_URIS: list = JARS,\n",
    "        SUBNETWORK_URIS: str = SUBNET,\n",
    "        FILE_URIS: list = [GCS_STAGING_LOCATION + \"/\" + LOG4J_PROPERTIES]\n",
    "    ):\n",
    "        for table in EXECUTION_LIST:\n",
    "            BATCH_ID = \"gcs2spanner-{}\".format(datetime.now().strftime(\"%s\"))\n",
    "            gcs_to_spanner_jobs.append(BATCH_ID)\n",
    "            TEMPLATE_SPARK_ARGS = [\n",
    "            \"--template=GCSTOSPANNER\",\n",
    "            \"--templateProperty\", \"project.id={}\".format(PROJECT),\n",
    "            \"-templateProperty\",  \"gcs.spanner.input.format={}\".format(MYSQL_OUTPUT_GCS_FORMAT),\n",
    "            \"--templateProperty\", \"gcs.spanner.input.location={}/{}/\".format(MYSQL_OUTPUT_GCS_LOCATION,table),\n",
    "            \"--templateProperty\", \"gcs.spanner.output.instance={}\".format(SPANNER_INSTANCE),\n",
    "            \"--templateProperty\", \"gcs.spanner.output.database={}\".format(SPANNER_DATABASE),\n",
    "            \"--templateProperty\", \"gcs.spanner.output.table={}\".format(table),\n",
    "            \"--templateProperty\", \"gcs.spanner.output.saveMode={}\".format(MYSQL_OUTPUT_GCS_MODE.capitalize()),\n",
    "            \"--templateProperty\", \"gcs.spanner.output.primaryKey={}\".format(SPANNER_TABLE_PRIMARY_KEYS[table])\n",
    "            ]\n",
    "            _ = DataprocSparkBatchOp(\n",
    "                project=PROJECT_ID,\n",
    "                location=LOCATION,\n",
    "                batch_id=BATCH_ID,\n",
    "                main_class=MAIN_CLASS,\n",
    "                jar_file_uris=JAR_FILE_URIS,\n",
    "                file_uris=FILE_URIS,\n",
    "                subnetwork_uri=SUBNETWORK_URIS,\n",
    "                args=TEMPLATE_SPARK_ARGS\n",
    "            )\n",
    "            time.sleep(3)\n",
    "                                                    \n",
    "\n",
    "    compiler.Compiler().compile(pipeline_func=pipeline, package_path=\"pipeline.json\")\n",
    "\n",
    "    pipeline = aiplatform.PipelineJob(\n",
    "            display_name=\"pipeline\",\n",
    "            template_path=\"pipeline.json\",\n",
    "            pipeline_root=PIPELINE_ROOT,\n",
    "            enable_caching=False,\n",
    "            )\n",
    "    pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f93c93a4-9621-418f-a004-673537c63bc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['employees', 'employees_nop']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.7/site-packages/kfp/v2/compiler/compiler.py:1295: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
      "  category=FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/617357862702/locations/us-central1/pipelineJobs/java-gcs-to-spanner-pyspark-20220901010416\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/617357862702/locations/us-central1/pipelineJobs/java-gcs-to-spanner-pyspark-20220901010416')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/java-gcs-to-spanner-pyspark-20220901010416?project=617357862702\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/java-gcs-to-spanner-pyspark-20220901010416 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/java-gcs-to-spanner-pyspark-20220901010416 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/java-gcs-to-spanner-pyspark-20220901010416 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/java-gcs-to-spanner-pyspark-20220901010416 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/java-gcs-to-spanner-pyspark-20220901010416 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/617357862702/locations/us-central1/pipelineJobs/java-gcs-to-spanner-pyspark-20220901010416\n",
      "['employees_mup']\n",
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/617357862702/locations/us-central1/pipelineJobs/java-gcs-to-spanner-pyspark-20220901010909\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/617357862702/locations/us-central1/pipelineJobs/java-gcs-to-spanner-pyspark-20220901010909')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/java-gcs-to-spanner-pyspark-20220901010909?project=617357862702\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/java-gcs-to-spanner-pyspark-20220901010909 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/java-gcs-to-spanner-pyspark-20220901010909 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/java-gcs-to-spanner-pyspark-20220901010909 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/java-gcs-to-spanner-pyspark-20220901010909 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/617357862702/locations/us-central1/pipelineJobs/java-gcs-to-spanner-pyspark-20220901010909 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/617357862702/locations/us-central1/pipelineJobs/java-gcs-to-spanner-pyspark-20220901010909\n"
     ]
    }
   ],
   "source": [
    "for execution_list in JOB_LIST:\n",
    "    print(execution_list)\n",
    "    migrate_gcs_to_spanner(execution_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85368f00-4d8a-4ea2-a1a6-53dc7e4e35f7",
   "metadata": {},
   "source": [
    "## Step 11: Get status for tables migrated from GCS to SPANNER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1bd1517-ed35-40fb-87de-d85fb84e7483",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bearer token generated\n"
     ]
    }
   ],
   "source": [
    "from google.auth.transport import requests\n",
    "import google\n",
    "\n",
    "token = get_bearer_token()\n",
    "if token[1] == 200:\n",
    "    print(\"Bearer token generated\")\n",
    "else:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e57b94e-3747-4d92-b67d-d342cddb193e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "gcs_to_spanner_status = []\n",
    "job_status_url = \"https://dataproc.googleapis.com/v1/projects/{}/locations/{}/batches/{}\"\n",
    "for job in gcs_to_spanner_jobs:\n",
    "    auth = \"Bearer \" + token[0]\n",
    "    url = job_status_url.format(PROJECT,REGION,job)\n",
    "    headers = {\n",
    "      'Content-Type': 'application/json; charset=UTF-8',\n",
    "      'Authorization': auth \n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    gcs_to_spanner_status.append(response.json()['state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c346cea-5dfb-4239-8caf-c56efa819f76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table</th>\n",
       "      <th>mysql_to_gcs_job</th>\n",
       "      <th>mysql_to_gcs_status</th>\n",
       "      <th>gcs_to_spanner_job</th>\n",
       "      <th>gcs_to_spanner_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>employees</td>\n",
       "      <td>mysql2gcs-1661993560</td>\n",
       "      <td>SUCCEEDED</td>\n",
       "      <td>gcs2spanner-1661994250</td>\n",
       "      <td>SUCCEEDED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>employees_nop</td>\n",
       "      <td>mysql2gcs-1661993563</td>\n",
       "      <td>SUCCEEDED</td>\n",
       "      <td>gcs2spanner-1661994253</td>\n",
       "      <td>SUCCEEDED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>employees_mup</td>\n",
       "      <td>mysql2gcs-1661993911</td>\n",
       "      <td>SUCCEEDED</td>\n",
       "      <td>gcs2spanner-1661994546</td>\n",
       "      <td>SUCCEEDED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           table      mysql_to_gcs_job mysql_to_gcs_status  \\\n",
       "0      employees  mysql2gcs-1661993560           SUCCEEDED   \n",
       "1  employees_nop  mysql2gcs-1661993563           SUCCEEDED   \n",
       "2  employees_mup  mysql2gcs-1661993911           SUCCEEDED   \n",
       "\n",
       "       gcs_to_spanner_job gcs_to_spanner_status  \n",
       "0  gcs2spanner-1661994250             SUCCEEDED  \n",
       "1  gcs2spanner-1661994253             SUCCEEDED  \n",
       "2  gcs2spanner-1661994546             SUCCEEDED  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statusDF['gcs_to_spanner_job'] = gcs_to_spanner_jobs\n",
    "statusDF['gcs_to_spanner_status'] = gcs_to_spanner_status\n",
    "statusDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0961f164-c7e4-4bb5-80f0-25fd1051147b",
   "metadata": {},
   "source": [
    "## Step 12: Validate row counts of migrated tables from MySQL to SPANNER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a3a28fb-3a39-4a10-b92d-0685b351a1b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mysql_row_count = []\n",
    "spanner_row_count = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "25299344-c167-4764-a5d1-56c1b384d104",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get mysql table counts\n",
    "DB = sqlalchemy.create_engine(\n",
    "            sqlalchemy.engine.url.URL.create(\n",
    "                drivername=PYMYSQL_DRIVER,\n",
    "                username=MYSQL_USERNAME,\n",
    "                password=MYSQL_PASSWORD,\n",
    "                database=MYSQL_DATABASE,\n",
    "                host=MYSQL_HOST,\n",
    "                port=MYSQL_PORT\n",
    "              )\n",
    "            )\n",
    "with DB.connect() as conn:\n",
    "    for table in MYSQLTABLE_LIST:\n",
    "        results = DB.execute(\"select count(*) from {}\".format(table)).fetchall()\n",
    "        for row in results:\n",
    "            mysql_row_count.append(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab0e539d-5180-4f5b-915e-35f7ea45e0d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18]\n",
      "[18]\n",
      "[18]\n"
     ]
    }
   ],
   "source": [
    "# get spanner table counts\n",
    "from google.cloud import spanner\n",
    "\n",
    "spanner_client = spanner.Client()\n",
    "instance = spanner_client.instance(SPANNER_INSTANCE)\n",
    "database = instance.database(SPANNER_DATABASE)\n",
    "\n",
    "for table in MYSQLTABLE_LIST:\n",
    "    with database.snapshot() as snapshot:\n",
    "        results = snapshot.execute_sql(\"select count(*) from {}\".format(table))\n",
    "        for row in results:\n",
    "            spanner_row_count.append(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4b1afe12-3eb9-4133-8377-66dc63ac649c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table</th>\n",
       "      <th>mysql_to_gcs_job</th>\n",
       "      <th>mysql_to_gcs_status</th>\n",
       "      <th>gcs_to_spanner_job</th>\n",
       "      <th>gcs_to_spanner_status</th>\n",
       "      <th>mysql_row_count</th>\n",
       "      <th>spanner_row_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>employees</td>\n",
       "      <td>mysql2gcs-1661993560</td>\n",
       "      <td>SUCCEEDED</td>\n",
       "      <td>gcs2spanner-1661994250</td>\n",
       "      <td>SUCCEEDED</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>employees_nop</td>\n",
       "      <td>mysql2gcs-1661993563</td>\n",
       "      <td>SUCCEEDED</td>\n",
       "      <td>gcs2spanner-1661994253</td>\n",
       "      <td>SUCCEEDED</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>employees_mup</td>\n",
       "      <td>mysql2gcs-1661993911</td>\n",
       "      <td>SUCCEEDED</td>\n",
       "      <td>gcs2spanner-1661994546</td>\n",
       "      <td>SUCCEEDED</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           table      mysql_to_gcs_job mysql_to_gcs_status  \\\n",
       "0      employees  mysql2gcs-1661993560           SUCCEEDED   \n",
       "1  employees_nop  mysql2gcs-1661993563           SUCCEEDED   \n",
       "2  employees_mup  mysql2gcs-1661993911           SUCCEEDED   \n",
       "\n",
       "       gcs_to_spanner_job gcs_to_spanner_status  mysql_row_count  \\\n",
       "0  gcs2spanner-1661994250             SUCCEEDED               18   \n",
       "1  gcs2spanner-1661994253             SUCCEEDED               18   \n",
       "2  gcs2spanner-1661994546             SUCCEEDED               18   \n",
       "\n",
       "   spanner_row_count  \n",
       "0                 18  \n",
       "1                 18  \n",
       "2                 18  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statusDF['mysql_row_count'] = mysql_row_count \n",
    "statusDF['spanner_row_count'] = spanner_row_count \n",
    "statusDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070961ea-7f3b-4f3c-afe1-647ee6981a95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m95",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m95"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
